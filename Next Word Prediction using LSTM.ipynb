{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3d46e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen=\"\"\"1 Introduction to Machine Learning\n",
    "Machine learning is a set of tools that, broadly speaking, allow us to “teach” computers how to\n",
    "perform tasks by providing examples of how they should be done. For example, suppose we wish\n",
    "to write a program to distinguish between valid email messages and unwanted spam. We could try\n",
    "to write a set of simple rules, for example, flagging messages that contain certain features (such\n",
    "as the word “viagra” or obviously-fake headers). However, writing rules to accurately distinguish\n",
    "which text is valid can actually be quite difficult to do well, resulting either in many missed spam\n",
    "messages, or, worse, many lost emails. Worse, the spammers will actively adjust the way they\n",
    "send spam in order to trick these strategies (e.g., writing “vi@gr@”). Writing effective rules —\n",
    "and keeping them up-to-date — quickly becomes an insurmountable task. Fortunately, machine\n",
    "learning has provided a solution. Modern spam filters are “learned” from examples: we provide the\n",
    "learning algorithm with example emails which we have manually labeled as “ham” (valid email)\n",
    "or “spam” (unwanted email), and the algorithms learn to distinguish between them automatically.\n",
    "Machine learning is a diverse and exciting field, and there are multiple ways of defining it:\n",
    "1. The Artifical Intelligence View. Learning is central to human knowledge and intelligence,\n",
    "and, likewise, it is also essential for building intelligent machines. Years of effort in AI\n",
    "has shown that trying to build intelligent computers by programming all the rules cannot be\n",
    "done; automatic learning is crucial. For example, we humans are not born with the ability\n",
    "to understand language — we learn it — and it makes sense to try to have computers learn\n",
    "language instead of trying to program it all it.\n",
    "2. The Software Engineering View. Machine learning allows us to program computers by\n",
    "example, which can be easier than writing code the traditional way.\n",
    "3. The Stats View. Machine learning is the marriage of computer science and statistics: computational\n",
    "techniques are applied to statistical problems. Machine learning has been applied\n",
    "to a vast number of problems in many contexts, beyond the typical statistics problems. Machine\n",
    "learning is often designed with different considerations than statistics (e.g., speed is\n",
    "often more important than accuracy).\n",
    "Often, machine learning methods are broken into two phases:\n",
    "1. Training: A model is learned from a collection of training data.\n",
    "2. Application: The model is used to make decisions about some new test data.\n",
    "For example, in the spam filtering case, the training data constitutes email messages labeled as ham\n",
    "or spam, and each new email message that we receive (and which to classify) is test data. However,\n",
    "there are other ways in which machine learning is used as well.\n",
    "Copyright c\n",
    " 2011 Aaron Hertzmann and David Fleet 1\n",
    "CSC 411 / CSC D11 Introduction to Machine Learning\n",
    "1.1 Types of Machine Learning\n",
    "Some of the main types of machine learning are:\n",
    "1. Supervised Learning, in which the training data is labeled with the correct answers, e.g.,\n",
    "“spam” or “ham.” The two most common types of supervised learning are classification\n",
    "(where the outputs are discrete labels, as in spam filtering) and regression (where the outputs\n",
    "are real-valued).\n",
    "2. Unsupervised learning, in which we are given a collection of unlabeled data, which we wish\n",
    "to analyze and discover patterns within. The two most important examples are dimension\n",
    "reduction and clustering.\n",
    "3. Reinforcement learning, in which an agent (e.g., a robot or controller) seeks to learn the\n",
    "optimal actions to take based the outcomes of past actions.\n",
    "There are many other types of machine learning as well, for example:\n",
    "1. Semi-supervised learning, in which only a subset of the training data is labeled\n",
    "2. Time-series forecasting, such as in financial markets\n",
    "3. Anomaly detection such as used for fault-detection in factories and in surveillance\n",
    "4. Active learning, in which obtaining data is expensive, and so an algorithm must determine\n",
    "which training data to acquire\n",
    "and many others.\n",
    "1.2 A simple problem\n",
    "Figure 1 shows a 1D regression problem. The goal is to fit a 1D curve to a few points. Which curve\n",
    "is best to fit these points? There are infinitely many curves that fit the data, and, because the data\n",
    "might be noisy, we might not even want to fit the data precisely. Hence, machine learning requires\n",
    "that we make certain choices:\n",
    "1. How do we parameterize the model we fit? For the example in Figure 1, how do we parameterize\n",
    "the curve; should we try to explain the data with a linear function, a quadratic, or a\n",
    "sinusoidal curve?\n",
    "2. What criteria (e.g., objective function) do we use to judge the quality of the fit? For example,\n",
    "when fitting a curve to noisy data, it is common to measure the quality of the fit in terms of\n",
    "the squared error between the data we are given and the fitted curve. When minimizing the\n",
    "squared error, the resulting fit is usually called a least-squares estimate.\n",
    "Copyright c\n",
    " 2011 Aaron Hertzmann and David Fleet 2\n",
    "CSC 411 / CSC D11 Introduction to Machine Learning\n",
    "3. Some types of models and some model parameters can be very expensive to optimize well.\n",
    "How long are we willing to wait for a solution, or can we use approximations (or handtuning)\n",
    "instead?\n",
    "4. Ideally we want to find a model that will provide useful predictions in future situations. That\n",
    "is, although we might learn a model from training data, we ultimately care about how well\n",
    "it works on future test data. When a model fits training data well, but performs poorly on\n",
    "test data, we say that the model has overfit the training data; i.e., the model has fit properties\n",
    "of the input that are not particularly relevant to the task at hand (e.g., Figures 1 (top row and\n",
    "bottom left)). Such properties are refered to as noise. When this happens we say that the\n",
    "model does not generalize well to the test data. Rather it produces predictions on the test\n",
    "data that are much less accurate than you might have hoped for given the fit to the training\n",
    "data.\n",
    "Machine learning provides a wide selection of options by which to answer these questions,\n",
    "along with the vast experience of the community as to which methods tend to be successful on\n",
    "a particular class of data-set. Some more advanced methods provide ways of automating some\n",
    "of these choices, such as automatically selecting between alternative models, and there is some\n",
    "beautiful theory that assists in gaining a deeper understanding of learning. In practice, there is no\n",
    "single “silver bullet” for all learning. Using machine learning in practice requires that you make\n",
    "use of your own prior knowledge and experimentation to solve problems. But with the tools of\n",
    "machine learning, you can do amazing things!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5163f70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2c11d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccede512",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([sen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbd588ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'to': 2,\n",
       " 'learning': 3,\n",
       " 'of': 4,\n",
       " 'a': 5,\n",
       " 'and': 6,\n",
       " 'we': 7,\n",
       " 'data': 8,\n",
       " 'is': 9,\n",
       " 'in': 10,\n",
       " 'machine': 11,\n",
       " 'are': 12,\n",
       " 'which': 13,\n",
       " 'that': 14,\n",
       " '1': 15,\n",
       " 'for': 16,\n",
       " 'as': 17,\n",
       " 'training': 18,\n",
       " 'model': 19,\n",
       " 'fit': 20,\n",
       " 'example': 21,\n",
       " 'or': 22,\n",
       " 'it': 23,\n",
       " 'be': 24,\n",
       " 'spam': 25,\n",
       " 'well': 26,\n",
       " 'e': 27,\n",
       " 'with': 28,\n",
       " '2': 29,\n",
       " 'some': 30,\n",
       " 'how': 31,\n",
       " 'many': 32,\n",
       " 'g': 33,\n",
       " 'there': 34,\n",
       " 'test': 35,\n",
       " 'curve': 36,\n",
       " 'email': 37,\n",
       " 'such': 38,\n",
       " 'can': 39,\n",
       " 'do': 40,\n",
       " 'has': 41,\n",
       " 'learn': 42,\n",
       " 'types': 43,\n",
       " 'computers': 44,\n",
       " 'by': 45,\n",
       " 'between': 46,\n",
       " 'messages': 47,\n",
       " 'rules': 48,\n",
       " 'writing': 49,\n",
       " 'these': 50,\n",
       " '—': 51,\n",
       " 'labeled': 52,\n",
       " 'not': 53,\n",
       " 'than': 54,\n",
       " '3': 55,\n",
       " 'problems': 56,\n",
       " 'csc': 57,\n",
       " 'might': 58,\n",
       " 'when': 59,\n",
       " 'on': 60,\n",
       " 'introduction': 61,\n",
       " 'set': 62,\n",
       " 'examples': 63,\n",
       " 'program': 64,\n",
       " 'distinguish': 65,\n",
       " 'valid': 66,\n",
       " 'try': 67,\n",
       " 'an': 68,\n",
       " 'from': 69,\n",
       " 'provide': 70,\n",
       " 'have': 71,\n",
       " 'ways': 72,\n",
       " 'view': 73,\n",
       " 'all': 74,\n",
       " 'statistics': 75,\n",
       " 'often': 76,\n",
       " 'methods': 77,\n",
       " 'two': 78,\n",
       " 'used': 79,\n",
       " 'make': 80,\n",
       " 'supervised': 81,\n",
       " 'given': 82,\n",
       " 'use': 83,\n",
       " 'you': 84,\n",
       " 'tools': 85,\n",
       " 'us': 86,\n",
       " 'they': 87,\n",
       " 'should': 88,\n",
       " 'done': 89,\n",
       " 'wish': 90,\n",
       " 'write': 91,\n",
       " 'unwanted': 92,\n",
       " 'simple': 93,\n",
       " 'certain': 94,\n",
       " 'however': 95,\n",
       " 'resulting': 96,\n",
       " 'worse': 97,\n",
       " 'emails': 98,\n",
       " 'will': 99,\n",
       " 'way': 100,\n",
       " '”': 101,\n",
       " 'them': 102,\n",
       " 'task': 103,\n",
       " 'solution': 104,\n",
       " 'algorithm': 105,\n",
       " '“spam”': 106,\n",
       " 'automatically': 107,\n",
       " 'intelligence': 108,\n",
       " 'knowledge': 109,\n",
       " 'intelligent': 110,\n",
       " 'trying': 111,\n",
       " 'language': 112,\n",
       " 'instead': 113,\n",
       " 'applied': 114,\n",
       " 'vast': 115,\n",
       " 'more': 116,\n",
       " 'important': 117,\n",
       " 'collection': 118,\n",
       " 'about': 119,\n",
       " 'new': 120,\n",
       " 'filtering': 121,\n",
       " 'other': 122,\n",
       " 'copyright': 123,\n",
       " 'c': 124,\n",
       " '2011': 125,\n",
       " 'aaron': 126,\n",
       " 'hertzmann': 127,\n",
       " 'david': 128,\n",
       " 'fleet': 129,\n",
       " '411': 130,\n",
       " 'd11': 131,\n",
       " 'most': 132,\n",
       " 'common': 133,\n",
       " 'where': 134,\n",
       " 'outputs': 135,\n",
       " 'regression': 136,\n",
       " 'actions': 137,\n",
       " 'detection': 138,\n",
       " '4': 139,\n",
       " 'expensive': 140,\n",
       " 'problem': 141,\n",
       " 'figure': 142,\n",
       " '1d': 143,\n",
       " 'points': 144,\n",
       " 'noisy': 145,\n",
       " 'want': 146,\n",
       " 'requires': 147,\n",
       " 'choices': 148,\n",
       " 'parameterize': 149,\n",
       " 'function': 150,\n",
       " 'quality': 151,\n",
       " 'squared': 152,\n",
       " 'error': 153,\n",
       " 'models': 154,\n",
       " 'predictions': 155,\n",
       " 'future': 156,\n",
       " 'but': 157,\n",
       " 'say': 158,\n",
       " 'properties': 159,\n",
       " 'practice': 160,\n",
       " 'broadly': 161,\n",
       " 'speaking': 162,\n",
       " 'allow': 163,\n",
       " '“teach”': 164,\n",
       " 'perform': 165,\n",
       " 'tasks': 166,\n",
       " 'providing': 167,\n",
       " 'suppose': 168,\n",
       " 'could': 169,\n",
       " 'flagging': 170,\n",
       " 'contain': 171,\n",
       " 'features': 172,\n",
       " 'word': 173,\n",
       " '“viagra”': 174,\n",
       " 'obviously': 175,\n",
       " 'fake': 176,\n",
       " 'headers': 177,\n",
       " 'accurately': 178,\n",
       " 'text': 179,\n",
       " 'actually': 180,\n",
       " 'quite': 181,\n",
       " 'difficult': 182,\n",
       " 'either': 183,\n",
       " 'missed': 184,\n",
       " 'lost': 185,\n",
       " 'spammers': 186,\n",
       " 'actively': 187,\n",
       " 'adjust': 188,\n",
       " 'send': 189,\n",
       " 'order': 190,\n",
       " 'trick': 191,\n",
       " 'strategies': 192,\n",
       " '“vi': 193,\n",
       " 'gr': 194,\n",
       " 'effective': 195,\n",
       " 'keeping': 196,\n",
       " 'up': 197,\n",
       " 'date': 198,\n",
       " 'quickly': 199,\n",
       " 'becomes': 200,\n",
       " 'insurmountable': 201,\n",
       " 'fortunately': 202,\n",
       " 'provided': 203,\n",
       " 'modern': 204,\n",
       " 'filters': 205,\n",
       " '“learned”': 206,\n",
       " 'manually': 207,\n",
       " '“ham”': 208,\n",
       " 'algorithms': 209,\n",
       " 'diverse': 210,\n",
       " 'exciting': 211,\n",
       " 'field': 212,\n",
       " 'multiple': 213,\n",
       " 'defining': 214,\n",
       " 'artifical': 215,\n",
       " 'central': 216,\n",
       " 'human': 217,\n",
       " 'likewise': 218,\n",
       " 'also': 219,\n",
       " 'essential': 220,\n",
       " 'building': 221,\n",
       " 'machines': 222,\n",
       " 'years': 223,\n",
       " 'effort': 224,\n",
       " 'ai': 225,\n",
       " 'shown': 226,\n",
       " 'build': 227,\n",
       " 'programming': 228,\n",
       " 'cannot': 229,\n",
       " 'automatic': 230,\n",
       " 'crucial': 231,\n",
       " 'humans': 232,\n",
       " 'born': 233,\n",
       " 'ability': 234,\n",
       " 'understand': 235,\n",
       " 'makes': 236,\n",
       " 'sense': 237,\n",
       " 'software': 238,\n",
       " 'engineering': 239,\n",
       " 'allows': 240,\n",
       " 'easier': 241,\n",
       " 'code': 242,\n",
       " 'traditional': 243,\n",
       " 'stats': 244,\n",
       " 'marriage': 245,\n",
       " 'computer': 246,\n",
       " 'science': 247,\n",
       " 'computational': 248,\n",
       " 'techniques': 249,\n",
       " 'statistical': 250,\n",
       " 'been': 251,\n",
       " 'number': 252,\n",
       " 'contexts': 253,\n",
       " 'beyond': 254,\n",
       " 'typical': 255,\n",
       " 'designed': 256,\n",
       " 'different': 257,\n",
       " 'considerations': 258,\n",
       " 'speed': 259,\n",
       " 'accuracy': 260,\n",
       " 'broken': 261,\n",
       " 'into': 262,\n",
       " 'phases': 263,\n",
       " 'learned': 264,\n",
       " 'application': 265,\n",
       " 'decisions': 266,\n",
       " 'case': 267,\n",
       " 'constitutes': 268,\n",
       " 'ham': 269,\n",
       " 'each': 270,\n",
       " 'message': 271,\n",
       " 'receive': 272,\n",
       " 'classify': 273,\n",
       " 'main': 274,\n",
       " 'correct': 275,\n",
       " 'answers': 276,\n",
       " '“ham': 277,\n",
       " 'classification': 278,\n",
       " 'discrete': 279,\n",
       " 'labels': 280,\n",
       " 'real': 281,\n",
       " 'valued': 282,\n",
       " 'unsupervised': 283,\n",
       " 'unlabeled': 284,\n",
       " 'analyze': 285,\n",
       " 'discover': 286,\n",
       " 'patterns': 287,\n",
       " 'within': 288,\n",
       " 'dimension': 289,\n",
       " 'reduction': 290,\n",
       " 'clustering': 291,\n",
       " 'reinforcement': 292,\n",
       " 'agent': 293,\n",
       " 'robot': 294,\n",
       " 'controller': 295,\n",
       " 'seeks': 296,\n",
       " 'optimal': 297,\n",
       " 'take': 298,\n",
       " 'based': 299,\n",
       " 'outcomes': 300,\n",
       " 'past': 301,\n",
       " 'semi': 302,\n",
       " 'only': 303,\n",
       " 'subset': 304,\n",
       " 'time': 305,\n",
       " 'series': 306,\n",
       " 'forecasting': 307,\n",
       " 'financial': 308,\n",
       " 'markets': 309,\n",
       " 'anomaly': 310,\n",
       " 'fault': 311,\n",
       " 'factories': 312,\n",
       " 'surveillance': 313,\n",
       " 'active': 314,\n",
       " 'obtaining': 315,\n",
       " 'so': 316,\n",
       " 'must': 317,\n",
       " 'determine': 318,\n",
       " 'acquire': 319,\n",
       " 'others': 320,\n",
       " 'shows': 321,\n",
       " 'goal': 322,\n",
       " 'few': 323,\n",
       " 'best': 324,\n",
       " 'infinitely': 325,\n",
       " 'curves': 326,\n",
       " 'because': 327,\n",
       " 'even': 328,\n",
       " 'precisely': 329,\n",
       " 'hence': 330,\n",
       " 'explain': 331,\n",
       " 'linear': 332,\n",
       " 'quadratic': 333,\n",
       " 'sinusoidal': 334,\n",
       " 'what': 335,\n",
       " 'criteria': 336,\n",
       " 'objective': 337,\n",
       " 'judge': 338,\n",
       " 'fitting': 339,\n",
       " 'measure': 340,\n",
       " 'terms': 341,\n",
       " 'fitted': 342,\n",
       " 'minimizing': 343,\n",
       " 'usually': 344,\n",
       " 'called': 345,\n",
       " 'least': 346,\n",
       " 'squares': 347,\n",
       " 'estimate': 348,\n",
       " 'parameters': 349,\n",
       " 'very': 350,\n",
       " 'optimize': 351,\n",
       " 'long': 352,\n",
       " 'willing': 353,\n",
       " 'wait': 354,\n",
       " 'approximations': 355,\n",
       " 'handtuning': 356,\n",
       " 'ideally': 357,\n",
       " 'find': 358,\n",
       " 'useful': 359,\n",
       " 'situations': 360,\n",
       " 'although': 361,\n",
       " 'ultimately': 362,\n",
       " 'care': 363,\n",
       " 'works': 364,\n",
       " 'fits': 365,\n",
       " 'performs': 366,\n",
       " 'poorly': 367,\n",
       " 'overfit': 368,\n",
       " 'i': 369,\n",
       " 'input': 370,\n",
       " 'particularly': 371,\n",
       " 'relevant': 372,\n",
       " 'at': 373,\n",
       " 'hand': 374,\n",
       " 'figures': 375,\n",
       " 'top': 376,\n",
       " 'row': 377,\n",
       " 'bottom': 378,\n",
       " 'left': 379,\n",
       " 'refered': 380,\n",
       " 'noise': 381,\n",
       " 'this': 382,\n",
       " 'happens': 383,\n",
       " 'does': 384,\n",
       " 'generalize': 385,\n",
       " 'rather': 386,\n",
       " 'produces': 387,\n",
       " 'much': 388,\n",
       " 'less': 389,\n",
       " 'accurate': 390,\n",
       " 'hoped': 391,\n",
       " 'provides': 392,\n",
       " 'wide': 393,\n",
       " 'selection': 394,\n",
       " 'options': 395,\n",
       " 'answer': 396,\n",
       " 'questions': 397,\n",
       " 'along': 398,\n",
       " 'experience': 399,\n",
       " 'community': 400,\n",
       " 'tend': 401,\n",
       " 'successful': 402,\n",
       " 'particular': 403,\n",
       " 'class': 404,\n",
       " 'advanced': 405,\n",
       " 'automating': 406,\n",
       " 'selecting': 407,\n",
       " 'alternative': 408,\n",
       " 'beautiful': 409,\n",
       " 'theory': 410,\n",
       " 'assists': 411,\n",
       " 'gaining': 412,\n",
       " 'deeper': 413,\n",
       " 'understanding': 414,\n",
       " 'no': 415,\n",
       " 'single': 416,\n",
       " '“silver': 417,\n",
       " 'bullet”': 418,\n",
       " 'using': 419,\n",
       " 'your': 420,\n",
       " 'own': 421,\n",
       " 'prior': 422,\n",
       " 'experimentation': 423,\n",
       " 'solve': 424,\n",
       " 'amazing': 425,\n",
       " 'things': 426}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a629ccb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0585da17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 61, 2, 11, 3]\n",
      "[11, 3, 9, 5, 62, 4, 85, 14, 161, 162, 163, 86, 2, 164, 44, 31, 2]\n",
      "[165, 166, 45, 167, 63, 4, 31, 87, 88, 24, 89, 16, 21, 168, 7, 90]\n",
      "[2, 91, 5, 64, 2, 65, 46, 66, 37, 47, 6, 92, 25, 7, 169, 67]\n",
      "[2, 91, 5, 62, 4, 93, 48, 16, 21, 170, 47, 14, 171, 94, 172, 38]\n",
      "[17, 1, 173, 174, 22, 175, 176, 177, 95, 49, 48, 2, 178, 65]\n",
      "[13, 179, 9, 66, 39, 180, 24, 181, 182, 2, 40, 26, 96, 183, 10, 32, 184, 25]\n",
      "[47, 22, 97, 32, 185, 98, 97, 1, 186, 99, 187, 188, 1, 100, 87]\n",
      "[189, 25, 10, 190, 2, 191, 50, 192, 27, 33, 49, 193, 194, 101, 49, 195, 48, 51]\n",
      "[6, 196, 102, 197, 2, 198, 51, 199, 200, 68, 201, 103, 202, 11]\n",
      "[3, 41, 203, 5, 104, 204, 25, 205, 12, 206, 69, 63, 7, 70, 1]\n",
      "[3, 105, 28, 21, 98, 13, 7, 71, 207, 52, 17, 208, 66, 37]\n",
      "[22, 106, 92, 37, 6, 1, 209, 42, 2, 65, 46, 102, 107]\n",
      "[11, 3, 9, 5, 210, 6, 211, 212, 6, 34, 12, 213, 72, 4, 214, 23]\n",
      "[15, 1, 215, 108, 73, 3, 9, 216, 2, 217, 109, 6, 108]\n",
      "[6, 218, 23, 9, 219, 220, 16, 221, 110, 222, 223, 4, 224, 10, 225]\n",
      "[41, 226, 14, 111, 2, 227, 110, 44, 45, 228, 74, 1, 48, 229, 24]\n",
      "[89, 230, 3, 9, 231, 16, 21, 7, 232, 12, 53, 233, 28, 1, 234]\n",
      "[2, 235, 112, 51, 7, 42, 23, 51, 6, 23, 236, 237, 2, 67, 2, 71, 44, 42]\n",
      "[112, 113, 4, 111, 2, 64, 23, 74, 23]\n",
      "[29, 1, 238, 239, 73, 11, 3, 240, 86, 2, 64, 44, 45]\n",
      "[21, 13, 39, 24, 241, 54, 49, 242, 1, 243, 100]\n",
      "[55, 1, 244, 73, 11, 3, 9, 1, 245, 4, 246, 247, 6, 75, 248]\n",
      "[249, 12, 114, 2, 250, 56, 11, 3, 41, 251, 114]\n",
      "[2, 5, 115, 252, 4, 56, 10, 32, 253, 254, 1, 255, 75, 56, 11]\n",
      "[3, 9, 76, 256, 28, 257, 258, 54, 75, 27, 33, 259, 9]\n",
      "[76, 116, 117, 54, 260]\n",
      "[76, 11, 3, 77, 12, 261, 262, 78, 263]\n",
      "[15, 18, 5, 19, 9, 264, 69, 5, 118, 4, 18, 8]\n",
      "[29, 265, 1, 19, 9, 79, 2, 80, 266, 119, 30, 120, 35, 8]\n",
      "[16, 21, 10, 1, 25, 121, 267, 1, 18, 8, 268, 37, 47, 52, 17, 269]\n",
      "[22, 25, 6, 270, 120, 37, 271, 14, 7, 272, 6, 13, 2, 273, 9, 35, 8, 95]\n",
      "[34, 12, 122, 72, 10, 13, 11, 3, 9, 79, 17, 26]\n",
      "[123, 124]\n",
      "[125, 126, 127, 6, 128, 129, 15]\n",
      "[57, 130, 57, 131, 61, 2, 11, 3]\n",
      "[15, 15, 43, 4, 11, 3]\n",
      "[30, 4, 1, 274, 43, 4, 11, 3, 12]\n",
      "[15, 81, 3, 10, 13, 1, 18, 8, 9, 52, 28, 1, 275, 276, 27, 33]\n",
      "[106, 22, 277, 101, 1, 78, 132, 133, 43, 4, 81, 3, 12, 278]\n",
      "[134, 1, 135, 12, 279, 280, 17, 10, 25, 121, 6, 136, 134, 1, 135]\n",
      "[12, 281, 282]\n",
      "[29, 283, 3, 10, 13, 7, 12, 82, 5, 118, 4, 284, 8, 13, 7, 90]\n",
      "[2, 285, 6, 286, 287, 288, 1, 78, 132, 117, 63, 12, 289]\n",
      "[290, 6, 291]\n",
      "[55, 292, 3, 10, 13, 68, 293, 27, 33, 5, 294, 22, 295, 296, 2, 42, 1]\n",
      "[297, 137, 2, 298, 299, 1, 300, 4, 301, 137]\n",
      "[34, 12, 32, 122, 43, 4, 11, 3, 17, 26, 16, 21]\n",
      "[15, 302, 81, 3, 10, 13, 303, 5, 304, 4, 1, 18, 8, 9, 52]\n",
      "[29, 305, 306, 307, 38, 17, 10, 308, 309]\n",
      "[55, 310, 138, 38, 17, 79, 16, 311, 138, 10, 312, 6, 10, 313]\n",
      "[139, 314, 3, 10, 13, 315, 8, 9, 140, 6, 316, 68, 105, 317, 318]\n",
      "[13, 18, 8, 2, 319]\n",
      "[6, 32, 320]\n",
      "[15, 29, 5, 93, 141]\n",
      "[142, 15, 321, 5, 143, 136, 141, 1, 322, 9, 2, 20, 5, 143, 36, 2, 5, 323, 144, 13, 36]\n",
      "[9, 324, 2, 20, 50, 144, 34, 12, 325, 32, 326, 14, 20, 1, 8, 6, 327, 1, 8]\n",
      "[58, 24, 145, 7, 58, 53, 328, 146, 2, 20, 1, 8, 329, 330, 11, 3, 147]\n",
      "[14, 7, 80, 94, 148]\n",
      "[15, 31, 40, 7, 149, 1, 19, 7, 20, 16, 1, 21, 10, 142, 15, 31, 40, 7, 149]\n",
      "[1, 36, 88, 7, 67, 2, 331, 1, 8, 28, 5, 332, 150, 5, 333, 22, 5]\n",
      "[334, 36]\n",
      "[29, 335, 336, 27, 33, 337, 150, 40, 7, 83, 2, 338, 1, 151, 4, 1, 20, 16, 21]\n",
      "[59, 339, 5, 36, 2, 145, 8, 23, 9, 133, 2, 340, 1, 151, 4, 1, 20, 10, 341, 4]\n",
      "[1, 152, 153, 46, 1, 8, 7, 12, 82, 6, 1, 342, 36, 59, 343, 1]\n",
      "[152, 153, 1, 96, 20, 9, 344, 345, 5, 346, 347, 348]\n",
      "[123, 124]\n",
      "[125, 126, 127, 6, 128, 129, 29]\n",
      "[57, 130, 57, 131, 61, 2, 11, 3]\n",
      "[55, 30, 43, 4, 154, 6, 30, 19, 349, 39, 24, 350, 140, 2, 351, 26]\n",
      "[31, 352, 12, 7, 353, 2, 354, 16, 5, 104, 22, 39, 7, 83, 355, 22, 356]\n",
      "[113]\n",
      "[139, 357, 7, 146, 2, 358, 5, 19, 14, 99, 70, 359, 155, 10, 156, 360, 14]\n",
      "[9, 361, 7, 58, 42, 5, 19, 69, 18, 8, 7, 362, 363, 119, 31, 26]\n",
      "[23, 364, 60, 156, 35, 8, 59, 5, 19, 365, 18, 8, 26, 157, 366, 367, 60]\n",
      "[35, 8, 7, 158, 14, 1, 19, 41, 368, 1, 18, 8, 369, 27, 1, 19, 41, 20, 159]\n",
      "[4, 1, 370, 14, 12, 53, 371, 372, 2, 1, 103, 373, 374, 27, 33, 375, 15, 376, 377, 6]\n",
      "[378, 379, 38, 159, 12, 380, 2, 17, 381, 59, 382, 383, 7, 158, 14, 1]\n",
      "[19, 384, 53, 385, 26, 2, 1, 35, 8, 386, 23, 387, 155, 60, 1, 35]\n",
      "[8, 14, 12, 388, 389, 390, 54, 84, 58, 71, 391, 16, 82, 1, 20, 2, 1, 18]\n",
      "[8]\n",
      "[11, 3, 392, 5, 393, 394, 4, 395, 45, 13, 2, 396, 50, 397]\n",
      "[398, 28, 1, 115, 399, 4, 1, 400, 17, 2, 13, 77, 401, 2, 24, 402, 60]\n",
      "[5, 403, 404, 4, 8, 62, 30, 116, 405, 77, 70, 72, 4, 406, 30]\n",
      "[4, 50, 148, 38, 17, 107, 407, 46, 408, 154, 6, 34, 9, 30]\n",
      "[409, 410, 14, 411, 10, 412, 5, 413, 414, 4, 3, 10, 160, 34, 9, 415]\n",
      "[416, 417, 418, 16, 74, 3, 419, 11, 3, 10, 160, 147, 14, 84, 80]\n",
      "[83, 4, 420, 421, 422, 109, 6, 423, 2, 424, 56, 157, 28, 1, 85, 4]\n",
      "[11, 3, 84, 39, 40, 425, 426]\n"
     ]
    }
   ],
   "source": [
    "for sentences in sen.split('\\n'):\n",
    "    tokenized_sen=tokenizer.texts_to_sequences([sentences])[0]\n",
    "    print(tokenized_sen)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2df320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_seq=[]\n",
    "for sentences in sen.split('\\n'):\n",
    "    tokenized_sen=tokenizer.texts_to_sequences([sentences])[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(1,len(tokenized_sen)):\n",
    "        inp_seq.append(tokenized_sen[:i+1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f6ac693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[15, 61],\n",
       " [15, 61, 2],\n",
       " [15, 61, 2, 11],\n",
       " [15, 61, 2, 11, 3],\n",
       " [11, 3],\n",
       " [11, 3, 9],\n",
       " [11, 3, 9, 5],\n",
       " [11, 3, 9, 5, 62],\n",
       " [11, 3, 9, 5, 62, 4],\n",
       " [11, 3, 9, 5, 62, 4, 85],\n",
       " [11, 3, 9, 5, 62, 4, 85, 14],\n",
       " [11, 3, 9, 5, 62, 4, 85, 14, 161],\n",
       " [11, 3, 9, 5, 62, 4, 85, 14, 161, 162],\n",
       " [11, 3, 9, 5, 62, 4, 85, 14, 161, 162, 163],\n",
       " [11, 3, 9, 5, 62, 4, 85, 14, 161, 162, 163, 86],\n",
       " [11, 3, 9, 5, 62, 4, 85, 14, 161, 162, 163, 86, 2],\n",
       " [11, 3, 9, 5, 62, 4, 85, 14, 161, 162, 163, 86, 2, 164],\n",
       " [11, 3, 9, 5, 62, 4, 85, 14, 161, 162, 163, 86, 2, 164, 44],\n",
       " [11, 3, 9, 5, 62, 4, 85, 14, 161, 162, 163, 86, 2, 164, 44, 31],\n",
       " [11, 3, 9, 5, 62, 4, 85, 14, 161, 162, 163, 86, 2, 164, 44, 31, 2],\n",
       " [165, 166],\n",
       " [165, 166, 45],\n",
       " [165, 166, 45, 167],\n",
       " [165, 166, 45, 167, 63],\n",
       " [165, 166, 45, 167, 63, 4],\n",
       " [165, 166, 45, 167, 63, 4, 31],\n",
       " [165, 166, 45, 167, 63, 4, 31, 87],\n",
       " [165, 166, 45, 167, 63, 4, 31, 87, 88],\n",
       " [165, 166, 45, 167, 63, 4, 31, 87, 88, 24],\n",
       " [165, 166, 45, 167, 63, 4, 31, 87, 88, 24, 89],\n",
       " [165, 166, 45, 167, 63, 4, 31, 87, 88, 24, 89, 16],\n",
       " [165, 166, 45, 167, 63, 4, 31, 87, 88, 24, 89, 16, 21],\n",
       " [165, 166, 45, 167, 63, 4, 31, 87, 88, 24, 89, 16, 21, 168],\n",
       " [165, 166, 45, 167, 63, 4, 31, 87, 88, 24, 89, 16, 21, 168, 7],\n",
       " [165, 166, 45, 167, 63, 4, 31, 87, 88, 24, 89, 16, 21, 168, 7, 90],\n",
       " [2, 91],\n",
       " [2, 91, 5],\n",
       " [2, 91, 5, 64],\n",
       " [2, 91, 5, 64, 2],\n",
       " [2, 91, 5, 64, 2, 65],\n",
       " [2, 91, 5, 64, 2, 65, 46],\n",
       " [2, 91, 5, 64, 2, 65, 46, 66],\n",
       " [2, 91, 5, 64, 2, 65, 46, 66, 37],\n",
       " [2, 91, 5, 64, 2, 65, 46, 66, 37, 47],\n",
       " [2, 91, 5, 64, 2, 65, 46, 66, 37, 47, 6],\n",
       " [2, 91, 5, 64, 2, 65, 46, 66, 37, 47, 6, 92],\n",
       " [2, 91, 5, 64, 2, 65, 46, 66, 37, 47, 6, 92, 25],\n",
       " [2, 91, 5, 64, 2, 65, 46, 66, 37, 47, 6, 92, 25, 7],\n",
       " [2, 91, 5, 64, 2, 65, 46, 66, 37, 47, 6, 92, 25, 7, 169],\n",
       " [2, 91, 5, 64, 2, 65, 46, 66, 37, 47, 6, 92, 25, 7, 169, 67],\n",
       " [2, 91],\n",
       " [2, 91, 5],\n",
       " [2, 91, 5, 62],\n",
       " [2, 91, 5, 62, 4],\n",
       " [2, 91, 5, 62, 4, 93],\n",
       " [2, 91, 5, 62, 4, 93, 48],\n",
       " [2, 91, 5, 62, 4, 93, 48, 16],\n",
       " [2, 91, 5, 62, 4, 93, 48, 16, 21],\n",
       " [2, 91, 5, 62, 4, 93, 48, 16, 21, 170],\n",
       " [2, 91, 5, 62, 4, 93, 48, 16, 21, 170, 47],\n",
       " [2, 91, 5, 62, 4, 93, 48, 16, 21, 170, 47, 14],\n",
       " [2, 91, 5, 62, 4, 93, 48, 16, 21, 170, 47, 14, 171],\n",
       " [2, 91, 5, 62, 4, 93, 48, 16, 21, 170, 47, 14, 171, 94],\n",
       " [2, 91, 5, 62, 4, 93, 48, 16, 21, 170, 47, 14, 171, 94, 172],\n",
       " [2, 91, 5, 62, 4, 93, 48, 16, 21, 170, 47, 14, 171, 94, 172, 38],\n",
       " [17, 1],\n",
       " [17, 1, 173],\n",
       " [17, 1, 173, 174],\n",
       " [17, 1, 173, 174, 22],\n",
       " [17, 1, 173, 174, 22, 175],\n",
       " [17, 1, 173, 174, 22, 175, 176],\n",
       " [17, 1, 173, 174, 22, 175, 176, 177],\n",
       " [17, 1, 173, 174, 22, 175, 176, 177, 95],\n",
       " [17, 1, 173, 174, 22, 175, 176, 177, 95, 49],\n",
       " [17, 1, 173, 174, 22, 175, 176, 177, 95, 49, 48],\n",
       " [17, 1, 173, 174, 22, 175, 176, 177, 95, 49, 48, 2],\n",
       " [17, 1, 173, 174, 22, 175, 176, 177, 95, 49, 48, 2, 178],\n",
       " [17, 1, 173, 174, 22, 175, 176, 177, 95, 49, 48, 2, 178, 65],\n",
       " [13, 179],\n",
       " [13, 179, 9],\n",
       " [13, 179, 9, 66],\n",
       " [13, 179, 9, 66, 39],\n",
       " [13, 179, 9, 66, 39, 180],\n",
       " [13, 179, 9, 66, 39, 180, 24],\n",
       " [13, 179, 9, 66, 39, 180, 24, 181],\n",
       " [13, 179, 9, 66, 39, 180, 24, 181, 182],\n",
       " [13, 179, 9, 66, 39, 180, 24, 181, 182, 2],\n",
       " [13, 179, 9, 66, 39, 180, 24, 181, 182, 2, 40],\n",
       " [13, 179, 9, 66, 39, 180, 24, 181, 182, 2, 40, 26],\n",
       " [13, 179, 9, 66, 39, 180, 24, 181, 182, 2, 40, 26, 96],\n",
       " [13, 179, 9, 66, 39, 180, 24, 181, 182, 2, 40, 26, 96, 183],\n",
       " [13, 179, 9, 66, 39, 180, 24, 181, 182, 2, 40, 26, 96, 183, 10],\n",
       " [13, 179, 9, 66, 39, 180, 24, 181, 182, 2, 40, 26, 96, 183, 10, 32],\n",
       " [13, 179, 9, 66, 39, 180, 24, 181, 182, 2, 40, 26, 96, 183, 10, 32, 184],\n",
       " [13, 179, 9, 66, 39, 180, 24, 181, 182, 2, 40, 26, 96, 183, 10, 32, 184, 25],\n",
       " [47, 22],\n",
       " [47, 22, 97],\n",
       " [47, 22, 97, 32],\n",
       " [47, 22, 97, 32, 185],\n",
       " [47, 22, 97, 32, 185, 98],\n",
       " [47, 22, 97, 32, 185, 98, 97],\n",
       " [47, 22, 97, 32, 185, 98, 97, 1],\n",
       " [47, 22, 97, 32, 185, 98, 97, 1, 186],\n",
       " [47, 22, 97, 32, 185, 98, 97, 1, 186, 99],\n",
       " [47, 22, 97, 32, 185, 98, 97, 1, 186, 99, 187],\n",
       " [47, 22, 97, 32, 185, 98, 97, 1, 186, 99, 187, 188],\n",
       " [47, 22, 97, 32, 185, 98, 97, 1, 186, 99, 187, 188, 1],\n",
       " [47, 22, 97, 32, 185, 98, 97, 1, 186, 99, 187, 188, 1, 100],\n",
       " [47, 22, 97, 32, 185, 98, 97, 1, 186, 99, 187, 188, 1, 100, 87],\n",
       " [189, 25],\n",
       " [189, 25, 10],\n",
       " [189, 25, 10, 190],\n",
       " [189, 25, 10, 190, 2],\n",
       " [189, 25, 10, 190, 2, 191],\n",
       " [189, 25, 10, 190, 2, 191, 50],\n",
       " [189, 25, 10, 190, 2, 191, 50, 192],\n",
       " [189, 25, 10, 190, 2, 191, 50, 192, 27],\n",
       " [189, 25, 10, 190, 2, 191, 50, 192, 27, 33],\n",
       " [189, 25, 10, 190, 2, 191, 50, 192, 27, 33, 49],\n",
       " [189, 25, 10, 190, 2, 191, 50, 192, 27, 33, 49, 193],\n",
       " [189, 25, 10, 190, 2, 191, 50, 192, 27, 33, 49, 193, 194],\n",
       " [189, 25, 10, 190, 2, 191, 50, 192, 27, 33, 49, 193, 194, 101],\n",
       " [189, 25, 10, 190, 2, 191, 50, 192, 27, 33, 49, 193, 194, 101, 49],\n",
       " [189, 25, 10, 190, 2, 191, 50, 192, 27, 33, 49, 193, 194, 101, 49, 195],\n",
       " [189, 25, 10, 190, 2, 191, 50, 192, 27, 33, 49, 193, 194, 101, 49, 195, 48],\n",
       " [189,\n",
       "  25,\n",
       "  10,\n",
       "  190,\n",
       "  2,\n",
       "  191,\n",
       "  50,\n",
       "  192,\n",
       "  27,\n",
       "  33,\n",
       "  49,\n",
       "  193,\n",
       "  194,\n",
       "  101,\n",
       "  49,\n",
       "  195,\n",
       "  48,\n",
       "  51],\n",
       " [6, 196],\n",
       " [6, 196, 102],\n",
       " [6, 196, 102, 197],\n",
       " [6, 196, 102, 197, 2],\n",
       " [6, 196, 102, 197, 2, 198],\n",
       " [6, 196, 102, 197, 2, 198, 51],\n",
       " [6, 196, 102, 197, 2, 198, 51, 199],\n",
       " [6, 196, 102, 197, 2, 198, 51, 199, 200],\n",
       " [6, 196, 102, 197, 2, 198, 51, 199, 200, 68],\n",
       " [6, 196, 102, 197, 2, 198, 51, 199, 200, 68, 201],\n",
       " [6, 196, 102, 197, 2, 198, 51, 199, 200, 68, 201, 103],\n",
       " [6, 196, 102, 197, 2, 198, 51, 199, 200, 68, 201, 103, 202],\n",
       " [6, 196, 102, 197, 2, 198, 51, 199, 200, 68, 201, 103, 202, 11],\n",
       " [3, 41],\n",
       " [3, 41, 203],\n",
       " [3, 41, 203, 5],\n",
       " [3, 41, 203, 5, 104],\n",
       " [3, 41, 203, 5, 104, 204],\n",
       " [3, 41, 203, 5, 104, 204, 25],\n",
       " [3, 41, 203, 5, 104, 204, 25, 205],\n",
       " [3, 41, 203, 5, 104, 204, 25, 205, 12],\n",
       " [3, 41, 203, 5, 104, 204, 25, 205, 12, 206],\n",
       " [3, 41, 203, 5, 104, 204, 25, 205, 12, 206, 69],\n",
       " [3, 41, 203, 5, 104, 204, 25, 205, 12, 206, 69, 63],\n",
       " [3, 41, 203, 5, 104, 204, 25, 205, 12, 206, 69, 63, 7],\n",
       " [3, 41, 203, 5, 104, 204, 25, 205, 12, 206, 69, 63, 7, 70],\n",
       " [3, 41, 203, 5, 104, 204, 25, 205, 12, 206, 69, 63, 7, 70, 1],\n",
       " [3, 105],\n",
       " [3, 105, 28],\n",
       " [3, 105, 28, 21],\n",
       " [3, 105, 28, 21, 98],\n",
       " [3, 105, 28, 21, 98, 13],\n",
       " [3, 105, 28, 21, 98, 13, 7],\n",
       " [3, 105, 28, 21, 98, 13, 7, 71],\n",
       " [3, 105, 28, 21, 98, 13, 7, 71, 207],\n",
       " [3, 105, 28, 21, 98, 13, 7, 71, 207, 52],\n",
       " [3, 105, 28, 21, 98, 13, 7, 71, 207, 52, 17],\n",
       " [3, 105, 28, 21, 98, 13, 7, 71, 207, 52, 17, 208],\n",
       " [3, 105, 28, 21, 98, 13, 7, 71, 207, 52, 17, 208, 66],\n",
       " [3, 105, 28, 21, 98, 13, 7, 71, 207, 52, 17, 208, 66, 37],\n",
       " [22, 106],\n",
       " [22, 106, 92],\n",
       " [22, 106, 92, 37],\n",
       " [22, 106, 92, 37, 6],\n",
       " [22, 106, 92, 37, 6, 1],\n",
       " [22, 106, 92, 37, 6, 1, 209],\n",
       " [22, 106, 92, 37, 6, 1, 209, 42],\n",
       " [22, 106, 92, 37, 6, 1, 209, 42, 2],\n",
       " [22, 106, 92, 37, 6, 1, 209, 42, 2, 65],\n",
       " [22, 106, 92, 37, 6, 1, 209, 42, 2, 65, 46],\n",
       " [22, 106, 92, 37, 6, 1, 209, 42, 2, 65, 46, 102],\n",
       " [22, 106, 92, 37, 6, 1, 209, 42, 2, 65, 46, 102, 107],\n",
       " [11, 3],\n",
       " [11, 3, 9],\n",
       " [11, 3, 9, 5],\n",
       " [11, 3, 9, 5, 210],\n",
       " [11, 3, 9, 5, 210, 6],\n",
       " [11, 3, 9, 5, 210, 6, 211],\n",
       " [11, 3, 9, 5, 210, 6, 211, 212],\n",
       " [11, 3, 9, 5, 210, 6, 211, 212, 6],\n",
       " [11, 3, 9, 5, 210, 6, 211, 212, 6, 34],\n",
       " [11, 3, 9, 5, 210, 6, 211, 212, 6, 34, 12],\n",
       " [11, 3, 9, 5, 210, 6, 211, 212, 6, 34, 12, 213],\n",
       " [11, 3, 9, 5, 210, 6, 211, 212, 6, 34, 12, 213, 72],\n",
       " [11, 3, 9, 5, 210, 6, 211, 212, 6, 34, 12, 213, 72, 4],\n",
       " [11, 3, 9, 5, 210, 6, 211, 212, 6, 34, 12, 213, 72, 4, 214],\n",
       " [11, 3, 9, 5, 210, 6, 211, 212, 6, 34, 12, 213, 72, 4, 214, 23],\n",
       " [15, 1],\n",
       " [15, 1, 215],\n",
       " [15, 1, 215, 108],\n",
       " [15, 1, 215, 108, 73],\n",
       " [15, 1, 215, 108, 73, 3],\n",
       " [15, 1, 215, 108, 73, 3, 9],\n",
       " [15, 1, 215, 108, 73, 3, 9, 216],\n",
       " [15, 1, 215, 108, 73, 3, 9, 216, 2],\n",
       " [15, 1, 215, 108, 73, 3, 9, 216, 2, 217],\n",
       " [15, 1, 215, 108, 73, 3, 9, 216, 2, 217, 109],\n",
       " [15, 1, 215, 108, 73, 3, 9, 216, 2, 217, 109, 6],\n",
       " [15, 1, 215, 108, 73, 3, 9, 216, 2, 217, 109, 6, 108],\n",
       " [6, 218],\n",
       " [6, 218, 23],\n",
       " [6, 218, 23, 9],\n",
       " [6, 218, 23, 9, 219],\n",
       " [6, 218, 23, 9, 219, 220],\n",
       " [6, 218, 23, 9, 219, 220, 16],\n",
       " [6, 218, 23, 9, 219, 220, 16, 221],\n",
       " [6, 218, 23, 9, 219, 220, 16, 221, 110],\n",
       " [6, 218, 23, 9, 219, 220, 16, 221, 110, 222],\n",
       " [6, 218, 23, 9, 219, 220, 16, 221, 110, 222, 223],\n",
       " [6, 218, 23, 9, 219, 220, 16, 221, 110, 222, 223, 4],\n",
       " [6, 218, 23, 9, 219, 220, 16, 221, 110, 222, 223, 4, 224],\n",
       " [6, 218, 23, 9, 219, 220, 16, 221, 110, 222, 223, 4, 224, 10],\n",
       " [6, 218, 23, 9, 219, 220, 16, 221, 110, 222, 223, 4, 224, 10, 225],\n",
       " [41, 226],\n",
       " [41, 226, 14],\n",
       " [41, 226, 14, 111],\n",
       " [41, 226, 14, 111, 2],\n",
       " [41, 226, 14, 111, 2, 227],\n",
       " [41, 226, 14, 111, 2, 227, 110],\n",
       " [41, 226, 14, 111, 2, 227, 110, 44],\n",
       " [41, 226, 14, 111, 2, 227, 110, 44, 45],\n",
       " [41, 226, 14, 111, 2, 227, 110, 44, 45, 228],\n",
       " [41, 226, 14, 111, 2, 227, 110, 44, 45, 228, 74],\n",
       " [41, 226, 14, 111, 2, 227, 110, 44, 45, 228, 74, 1],\n",
       " [41, 226, 14, 111, 2, 227, 110, 44, 45, 228, 74, 1, 48],\n",
       " [41, 226, 14, 111, 2, 227, 110, 44, 45, 228, 74, 1, 48, 229],\n",
       " [41, 226, 14, 111, 2, 227, 110, 44, 45, 228, 74, 1, 48, 229, 24],\n",
       " [89, 230],\n",
       " [89, 230, 3],\n",
       " [89, 230, 3, 9],\n",
       " [89, 230, 3, 9, 231],\n",
       " [89, 230, 3, 9, 231, 16],\n",
       " [89, 230, 3, 9, 231, 16, 21],\n",
       " [89, 230, 3, 9, 231, 16, 21, 7],\n",
       " [89, 230, 3, 9, 231, 16, 21, 7, 232],\n",
       " [89, 230, 3, 9, 231, 16, 21, 7, 232, 12],\n",
       " [89, 230, 3, 9, 231, 16, 21, 7, 232, 12, 53],\n",
       " [89, 230, 3, 9, 231, 16, 21, 7, 232, 12, 53, 233],\n",
       " [89, 230, 3, 9, 231, 16, 21, 7, 232, 12, 53, 233, 28],\n",
       " [89, 230, 3, 9, 231, 16, 21, 7, 232, 12, 53, 233, 28, 1],\n",
       " [89, 230, 3, 9, 231, 16, 21, 7, 232, 12, 53, 233, 28, 1, 234],\n",
       " [2, 235],\n",
       " [2, 235, 112],\n",
       " [2, 235, 112, 51],\n",
       " [2, 235, 112, 51, 7],\n",
       " [2, 235, 112, 51, 7, 42],\n",
       " [2, 235, 112, 51, 7, 42, 23],\n",
       " [2, 235, 112, 51, 7, 42, 23, 51],\n",
       " [2, 235, 112, 51, 7, 42, 23, 51, 6],\n",
       " [2, 235, 112, 51, 7, 42, 23, 51, 6, 23],\n",
       " [2, 235, 112, 51, 7, 42, 23, 51, 6, 23, 236],\n",
       " [2, 235, 112, 51, 7, 42, 23, 51, 6, 23, 236, 237],\n",
       " [2, 235, 112, 51, 7, 42, 23, 51, 6, 23, 236, 237, 2],\n",
       " [2, 235, 112, 51, 7, 42, 23, 51, 6, 23, 236, 237, 2, 67],\n",
       " [2, 235, 112, 51, 7, 42, 23, 51, 6, 23, 236, 237, 2, 67, 2],\n",
       " [2, 235, 112, 51, 7, 42, 23, 51, 6, 23, 236, 237, 2, 67, 2, 71],\n",
       " [2, 235, 112, 51, 7, 42, 23, 51, 6, 23, 236, 237, 2, 67, 2, 71, 44],\n",
       " [2, 235, 112, 51, 7, 42, 23, 51, 6, 23, 236, 237, 2, 67, 2, 71, 44, 42],\n",
       " [112, 113],\n",
       " [112, 113, 4],\n",
       " [112, 113, 4, 111],\n",
       " [112, 113, 4, 111, 2],\n",
       " [112, 113, 4, 111, 2, 64],\n",
       " [112, 113, 4, 111, 2, 64, 23],\n",
       " [112, 113, 4, 111, 2, 64, 23, 74],\n",
       " [112, 113, 4, 111, 2, 64, 23, 74, 23],\n",
       " [29, 1],\n",
       " [29, 1, 238],\n",
       " [29, 1, 238, 239],\n",
       " [29, 1, 238, 239, 73],\n",
       " [29, 1, 238, 239, 73, 11],\n",
       " [29, 1, 238, 239, 73, 11, 3],\n",
       " [29, 1, 238, 239, 73, 11, 3, 240],\n",
       " [29, 1, 238, 239, 73, 11, 3, 240, 86],\n",
       " [29, 1, 238, 239, 73, 11, 3, 240, 86, 2],\n",
       " [29, 1, 238, 239, 73, 11, 3, 240, 86, 2, 64],\n",
       " [29, 1, 238, 239, 73, 11, 3, 240, 86, 2, 64, 44],\n",
       " [29, 1, 238, 239, 73, 11, 3, 240, 86, 2, 64, 44, 45],\n",
       " [21, 13],\n",
       " [21, 13, 39],\n",
       " [21, 13, 39, 24],\n",
       " [21, 13, 39, 24, 241],\n",
       " [21, 13, 39, 24, 241, 54],\n",
       " [21, 13, 39, 24, 241, 54, 49],\n",
       " [21, 13, 39, 24, 241, 54, 49, 242],\n",
       " [21, 13, 39, 24, 241, 54, 49, 242, 1],\n",
       " [21, 13, 39, 24, 241, 54, 49, 242, 1, 243],\n",
       " [21, 13, 39, 24, 241, 54, 49, 242, 1, 243, 100],\n",
       " [55, 1],\n",
       " [55, 1, 244],\n",
       " [55, 1, 244, 73],\n",
       " [55, 1, 244, 73, 11],\n",
       " [55, 1, 244, 73, 11, 3],\n",
       " [55, 1, 244, 73, 11, 3, 9],\n",
       " [55, 1, 244, 73, 11, 3, 9, 1],\n",
       " [55, 1, 244, 73, 11, 3, 9, 1, 245],\n",
       " [55, 1, 244, 73, 11, 3, 9, 1, 245, 4],\n",
       " [55, 1, 244, 73, 11, 3, 9, 1, 245, 4, 246],\n",
       " [55, 1, 244, 73, 11, 3, 9, 1, 245, 4, 246, 247],\n",
       " [55, 1, 244, 73, 11, 3, 9, 1, 245, 4, 246, 247, 6],\n",
       " [55, 1, 244, 73, 11, 3, 9, 1, 245, 4, 246, 247, 6, 75],\n",
       " [55, 1, 244, 73, 11, 3, 9, 1, 245, 4, 246, 247, 6, 75, 248],\n",
       " [249, 12],\n",
       " [249, 12, 114],\n",
       " [249, 12, 114, 2],\n",
       " [249, 12, 114, 2, 250],\n",
       " [249, 12, 114, 2, 250, 56],\n",
       " [249, 12, 114, 2, 250, 56, 11],\n",
       " [249, 12, 114, 2, 250, 56, 11, 3],\n",
       " [249, 12, 114, 2, 250, 56, 11, 3, 41],\n",
       " [249, 12, 114, 2, 250, 56, 11, 3, 41, 251],\n",
       " [249, 12, 114, 2, 250, 56, 11, 3, 41, 251, 114],\n",
       " [2, 5],\n",
       " [2, 5, 115],\n",
       " [2, 5, 115, 252],\n",
       " [2, 5, 115, 252, 4],\n",
       " [2, 5, 115, 252, 4, 56],\n",
       " [2, 5, 115, 252, 4, 56, 10],\n",
       " [2, 5, 115, 252, 4, 56, 10, 32],\n",
       " [2, 5, 115, 252, 4, 56, 10, 32, 253],\n",
       " [2, 5, 115, 252, 4, 56, 10, 32, 253, 254],\n",
       " [2, 5, 115, 252, 4, 56, 10, 32, 253, 254, 1],\n",
       " [2, 5, 115, 252, 4, 56, 10, 32, 253, 254, 1, 255],\n",
       " [2, 5, 115, 252, 4, 56, 10, 32, 253, 254, 1, 255, 75],\n",
       " [2, 5, 115, 252, 4, 56, 10, 32, 253, 254, 1, 255, 75, 56],\n",
       " [2, 5, 115, 252, 4, 56, 10, 32, 253, 254, 1, 255, 75, 56, 11],\n",
       " [3, 9],\n",
       " [3, 9, 76],\n",
       " [3, 9, 76, 256],\n",
       " [3, 9, 76, 256, 28],\n",
       " [3, 9, 76, 256, 28, 257],\n",
       " [3, 9, 76, 256, 28, 257, 258],\n",
       " [3, 9, 76, 256, 28, 257, 258, 54],\n",
       " [3, 9, 76, 256, 28, 257, 258, 54, 75],\n",
       " [3, 9, 76, 256, 28, 257, 258, 54, 75, 27],\n",
       " [3, 9, 76, 256, 28, 257, 258, 54, 75, 27, 33],\n",
       " [3, 9, 76, 256, 28, 257, 258, 54, 75, 27, 33, 259],\n",
       " [3, 9, 76, 256, 28, 257, 258, 54, 75, 27, 33, 259, 9],\n",
       " [76, 116],\n",
       " [76, 116, 117],\n",
       " [76, 116, 117, 54],\n",
       " [76, 116, 117, 54, 260],\n",
       " [76, 11],\n",
       " [76, 11, 3],\n",
       " [76, 11, 3, 77],\n",
       " [76, 11, 3, 77, 12],\n",
       " [76, 11, 3, 77, 12, 261],\n",
       " [76, 11, 3, 77, 12, 261, 262],\n",
       " [76, 11, 3, 77, 12, 261, 262, 78],\n",
       " [76, 11, 3, 77, 12, 261, 262, 78, 263],\n",
       " [15, 18],\n",
       " [15, 18, 5],\n",
       " [15, 18, 5, 19],\n",
       " [15, 18, 5, 19, 9],\n",
       " [15, 18, 5, 19, 9, 264],\n",
       " [15, 18, 5, 19, 9, 264, 69],\n",
       " [15, 18, 5, 19, 9, 264, 69, 5],\n",
       " [15, 18, 5, 19, 9, 264, 69, 5, 118],\n",
       " [15, 18, 5, 19, 9, 264, 69, 5, 118, 4],\n",
       " [15, 18, 5, 19, 9, 264, 69, 5, 118, 4, 18],\n",
       " [15, 18, 5, 19, 9, 264, 69, 5, 118, 4, 18, 8],\n",
       " [29, 265],\n",
       " [29, 265, 1],\n",
       " [29, 265, 1, 19],\n",
       " [29, 265, 1, 19, 9],\n",
       " [29, 265, 1, 19, 9, 79],\n",
       " [29, 265, 1, 19, 9, 79, 2],\n",
       " [29, 265, 1, 19, 9, 79, 2, 80],\n",
       " [29, 265, 1, 19, 9, 79, 2, 80, 266],\n",
       " [29, 265, 1, 19, 9, 79, 2, 80, 266, 119],\n",
       " [29, 265, 1, 19, 9, 79, 2, 80, 266, 119, 30],\n",
       " [29, 265, 1, 19, 9, 79, 2, 80, 266, 119, 30, 120],\n",
       " [29, 265, 1, 19, 9, 79, 2, 80, 266, 119, 30, 120, 35],\n",
       " [29, 265, 1, 19, 9, 79, 2, 80, 266, 119, 30, 120, 35, 8],\n",
       " [16, 21],\n",
       " [16, 21, 10],\n",
       " [16, 21, 10, 1],\n",
       " [16, 21, 10, 1, 25],\n",
       " [16, 21, 10, 1, 25, 121],\n",
       " [16, 21, 10, 1, 25, 121, 267],\n",
       " [16, 21, 10, 1, 25, 121, 267, 1],\n",
       " [16, 21, 10, 1, 25, 121, 267, 1, 18],\n",
       " [16, 21, 10, 1, 25, 121, 267, 1, 18, 8],\n",
       " [16, 21, 10, 1, 25, 121, 267, 1, 18, 8, 268],\n",
       " [16, 21, 10, 1, 25, 121, 267, 1, 18, 8, 268, 37],\n",
       " [16, 21, 10, 1, 25, 121, 267, 1, 18, 8, 268, 37, 47],\n",
       " [16, 21, 10, 1, 25, 121, 267, 1, 18, 8, 268, 37, 47, 52],\n",
       " [16, 21, 10, 1, 25, 121, 267, 1, 18, 8, 268, 37, 47, 52, 17],\n",
       " [16, 21, 10, 1, 25, 121, 267, 1, 18, 8, 268, 37, 47, 52, 17, 269],\n",
       " [22, 25],\n",
       " [22, 25, 6],\n",
       " [22, 25, 6, 270],\n",
       " [22, 25, 6, 270, 120],\n",
       " [22, 25, 6, 270, 120, 37],\n",
       " [22, 25, 6, 270, 120, 37, 271],\n",
       " [22, 25, 6, 270, 120, 37, 271, 14],\n",
       " [22, 25, 6, 270, 120, 37, 271, 14, 7],\n",
       " [22, 25, 6, 270, 120, 37, 271, 14, 7, 272],\n",
       " [22, 25, 6, 270, 120, 37, 271, 14, 7, 272, 6],\n",
       " [22, 25, 6, 270, 120, 37, 271, 14, 7, 272, 6, 13],\n",
       " [22, 25, 6, 270, 120, 37, 271, 14, 7, 272, 6, 13, 2],\n",
       " [22, 25, 6, 270, 120, 37, 271, 14, 7, 272, 6, 13, 2, 273],\n",
       " [22, 25, 6, 270, 120, 37, 271, 14, 7, 272, 6, 13, 2, 273, 9],\n",
       " [22, 25, 6, 270, 120, 37, 271, 14, 7, 272, 6, 13, 2, 273, 9, 35],\n",
       " [22, 25, 6, 270, 120, 37, 271, 14, 7, 272, 6, 13, 2, 273, 9, 35, 8],\n",
       " [22, 25, 6, 270, 120, 37, 271, 14, 7, 272, 6, 13, 2, 273, 9, 35, 8, 95],\n",
       " [34, 12],\n",
       " [34, 12, 122],\n",
       " [34, 12, 122, 72],\n",
       " [34, 12, 122, 72, 10],\n",
       " [34, 12, 122, 72, 10, 13],\n",
       " [34, 12, 122, 72, 10, 13, 11],\n",
       " [34, 12, 122, 72, 10, 13, 11, 3],\n",
       " [34, 12, 122, 72, 10, 13, 11, 3, 9],\n",
       " [34, 12, 122, 72, 10, 13, 11, 3, 9, 79],\n",
       " [34, 12, 122, 72, 10, 13, 11, 3, 9, 79, 17],\n",
       " [34, 12, 122, 72, 10, 13, 11, 3, 9, 79, 17, 26],\n",
       " [123, 124],\n",
       " [125, 126],\n",
       " [125, 126, 127],\n",
       " [125, 126, 127, 6],\n",
       " [125, 126, 127, 6, 128],\n",
       " [125, 126, 127, 6, 128, 129],\n",
       " [125, 126, 127, 6, 128, 129, 15],\n",
       " [57, 130],\n",
       " [57, 130, 57],\n",
       " [57, 130, 57, 131],\n",
       " [57, 130, 57, 131, 61],\n",
       " [57, 130, 57, 131, 61, 2],\n",
       " [57, 130, 57, 131, 61, 2, 11],\n",
       " [57, 130, 57, 131, 61, 2, 11, 3],\n",
       " [15, 15],\n",
       " [15, 15, 43],\n",
       " [15, 15, 43, 4],\n",
       " [15, 15, 43, 4, 11],\n",
       " [15, 15, 43, 4, 11, 3],\n",
       " [30, 4],\n",
       " [30, 4, 1],\n",
       " [30, 4, 1, 274],\n",
       " [30, 4, 1, 274, 43],\n",
       " [30, 4, 1, 274, 43, 4],\n",
       " [30, 4, 1, 274, 43, 4, 11],\n",
       " [30, 4, 1, 274, 43, 4, 11, 3],\n",
       " [30, 4, 1, 274, 43, 4, 11, 3, 12],\n",
       " [15, 81],\n",
       " [15, 81, 3],\n",
       " [15, 81, 3, 10],\n",
       " [15, 81, 3, 10, 13],\n",
       " [15, 81, 3, 10, 13, 1],\n",
       " [15, 81, 3, 10, 13, 1, 18],\n",
       " [15, 81, 3, 10, 13, 1, 18, 8],\n",
       " [15, 81, 3, 10, 13, 1, 18, 8, 9],\n",
       " [15, 81, 3, 10, 13, 1, 18, 8, 9, 52],\n",
       " [15, 81, 3, 10, 13, 1, 18, 8, 9, 52, 28],\n",
       " [15, 81, 3, 10, 13, 1, 18, 8, 9, 52, 28, 1],\n",
       " [15, 81, 3, 10, 13, 1, 18, 8, 9, 52, 28, 1, 275],\n",
       " [15, 81, 3, 10, 13, 1, 18, 8, 9, 52, 28, 1, 275, 276],\n",
       " [15, 81, 3, 10, 13, 1, 18, 8, 9, 52, 28, 1, 275, 276, 27],\n",
       " [15, 81, 3, 10, 13, 1, 18, 8, 9, 52, 28, 1, 275, 276, 27, 33],\n",
       " [106, 22],\n",
       " [106, 22, 277],\n",
       " [106, 22, 277, 101],\n",
       " [106, 22, 277, 101, 1],\n",
       " [106, 22, 277, 101, 1, 78],\n",
       " [106, 22, 277, 101, 1, 78, 132],\n",
       " [106, 22, 277, 101, 1, 78, 132, 133],\n",
       " [106, 22, 277, 101, 1, 78, 132, 133, 43],\n",
       " [106, 22, 277, 101, 1, 78, 132, 133, 43, 4],\n",
       " [106, 22, 277, 101, 1, 78, 132, 133, 43, 4, 81],\n",
       " [106, 22, 277, 101, 1, 78, 132, 133, 43, 4, 81, 3],\n",
       " [106, 22, 277, 101, 1, 78, 132, 133, 43, 4, 81, 3, 12],\n",
       " [106, 22, 277, 101, 1, 78, 132, 133, 43, 4, 81, 3, 12, 278],\n",
       " [134, 1],\n",
       " [134, 1, 135],\n",
       " [134, 1, 135, 12],\n",
       " [134, 1, 135, 12, 279],\n",
       " [134, 1, 135, 12, 279, 280],\n",
       " [134, 1, 135, 12, 279, 280, 17],\n",
       " [134, 1, 135, 12, 279, 280, 17, 10],\n",
       " [134, 1, 135, 12, 279, 280, 17, 10, 25],\n",
       " [134, 1, 135, 12, 279, 280, 17, 10, 25, 121],\n",
       " [134, 1, 135, 12, 279, 280, 17, 10, 25, 121, 6],\n",
       " [134, 1, 135, 12, 279, 280, 17, 10, 25, 121, 6, 136],\n",
       " [134, 1, 135, 12, 279, 280, 17, 10, 25, 121, 6, 136, 134],\n",
       " [134, 1, 135, 12, 279, 280, 17, 10, 25, 121, 6, 136, 134, 1],\n",
       " [134, 1, 135, 12, 279, 280, 17, 10, 25, 121, 6, 136, 134, 1, 135],\n",
       " [12, 281],\n",
       " [12, 281, 282],\n",
       " [29, 283],\n",
       " [29, 283, 3],\n",
       " [29, 283, 3, 10],\n",
       " [29, 283, 3, 10, 13],\n",
       " [29, 283, 3, 10, 13, 7],\n",
       " [29, 283, 3, 10, 13, 7, 12],\n",
       " [29, 283, 3, 10, 13, 7, 12, 82],\n",
       " [29, 283, 3, 10, 13, 7, 12, 82, 5],\n",
       " [29, 283, 3, 10, 13, 7, 12, 82, 5, 118],\n",
       " [29, 283, 3, 10, 13, 7, 12, 82, 5, 118, 4],\n",
       " [29, 283, 3, 10, 13, 7, 12, 82, 5, 118, 4, 284],\n",
       " [29, 283, 3, 10, 13, 7, 12, 82, 5, 118, 4, 284, 8],\n",
       " [29, 283, 3, 10, 13, 7, 12, 82, 5, 118, 4, 284, 8, 13],\n",
       " [29, 283, 3, 10, 13, 7, 12, 82, 5, 118, 4, 284, 8, 13, 7],\n",
       " [29, 283, 3, 10, 13, 7, 12, 82, 5, 118, 4, 284, 8, 13, 7, 90],\n",
       " [2, 285],\n",
       " [2, 285, 6],\n",
       " [2, 285, 6, 286],\n",
       " [2, 285, 6, 286, 287],\n",
       " [2, 285, 6, 286, 287, 288],\n",
       " [2, 285, 6, 286, 287, 288, 1],\n",
       " [2, 285, 6, 286, 287, 288, 1, 78],\n",
       " [2, 285, 6, 286, 287, 288, 1, 78, 132],\n",
       " [2, 285, 6, 286, 287, 288, 1, 78, 132, 117],\n",
       " [2, 285, 6, 286, 287, 288, 1, 78, 132, 117, 63],\n",
       " [2, 285, 6, 286, 287, 288, 1, 78, 132, 117, 63, 12],\n",
       " [2, 285, 6, 286, 287, 288, 1, 78, 132, 117, 63, 12, 289],\n",
       " [290, 6],\n",
       " [290, 6, 291],\n",
       " [55, 292],\n",
       " [55, 292, 3],\n",
       " [55, 292, 3, 10],\n",
       " [55, 292, 3, 10, 13],\n",
       " [55, 292, 3, 10, 13, 68],\n",
       " [55, 292, 3, 10, 13, 68, 293],\n",
       " [55, 292, 3, 10, 13, 68, 293, 27],\n",
       " [55, 292, 3, 10, 13, 68, 293, 27, 33],\n",
       " [55, 292, 3, 10, 13, 68, 293, 27, 33, 5],\n",
       " [55, 292, 3, 10, 13, 68, 293, 27, 33, 5, 294],\n",
       " [55, 292, 3, 10, 13, 68, 293, 27, 33, 5, 294, 22],\n",
       " [55, 292, 3, 10, 13, 68, 293, 27, 33, 5, 294, 22, 295],\n",
       " [55, 292, 3, 10, 13, 68, 293, 27, 33, 5, 294, 22, 295, 296],\n",
       " [55, 292, 3, 10, 13, 68, 293, 27, 33, 5, 294, 22, 295, 296, 2],\n",
       " [55, 292, 3, 10, 13, 68, 293, 27, 33, 5, 294, 22, 295, 296, 2, 42],\n",
       " [55, 292, 3, 10, 13, 68, 293, 27, 33, 5, 294, 22, 295, 296, 2, 42, 1],\n",
       " [297, 137],\n",
       " [297, 137, 2],\n",
       " [297, 137, 2, 298],\n",
       " [297, 137, 2, 298, 299],\n",
       " [297, 137, 2, 298, 299, 1],\n",
       " [297, 137, 2, 298, 299, 1, 300],\n",
       " [297, 137, 2, 298, 299, 1, 300, 4],\n",
       " [297, 137, 2, 298, 299, 1, 300, 4, 301],\n",
       " [297, 137, 2, 298, 299, 1, 300, 4, 301, 137],\n",
       " [34, 12],\n",
       " [34, 12, 32],\n",
       " [34, 12, 32, 122],\n",
       " [34, 12, 32, 122, 43],\n",
       " [34, 12, 32, 122, 43, 4],\n",
       " [34, 12, 32, 122, 43, 4, 11],\n",
       " [34, 12, 32, 122, 43, 4, 11, 3],\n",
       " [34, 12, 32, 122, 43, 4, 11, 3, 17],\n",
       " [34, 12, 32, 122, 43, 4, 11, 3, 17, 26],\n",
       " [34, 12, 32, 122, 43, 4, 11, 3, 17, 26, 16],\n",
       " [34, 12, 32, 122, 43, 4, 11, 3, 17, 26, 16, 21],\n",
       " [15, 302],\n",
       " [15, 302, 81],\n",
       " [15, 302, 81, 3],\n",
       " [15, 302, 81, 3, 10],\n",
       " [15, 302, 81, 3, 10, 13],\n",
       " [15, 302, 81, 3, 10, 13, 303],\n",
       " [15, 302, 81, 3, 10, 13, 303, 5],\n",
       " [15, 302, 81, 3, 10, 13, 303, 5, 304],\n",
       " [15, 302, 81, 3, 10, 13, 303, 5, 304, 4],\n",
       " [15, 302, 81, 3, 10, 13, 303, 5, 304, 4, 1],\n",
       " [15, 302, 81, 3, 10, 13, 303, 5, 304, 4, 1, 18],\n",
       " [15, 302, 81, 3, 10, 13, 303, 5, 304, 4, 1, 18, 8],\n",
       " [15, 302, 81, 3, 10, 13, 303, 5, 304, 4, 1, 18, 8, 9],\n",
       " [15, 302, 81, 3, 10, 13, 303, 5, 304, 4, 1, 18, 8, 9, 52],\n",
       " [29, 305],\n",
       " [29, 305, 306],\n",
       " [29, 305, 306, 307],\n",
       " [29, 305, 306, 307, 38],\n",
       " [29, 305, 306, 307, 38, 17],\n",
       " [29, 305, 306, 307, 38, 17, 10],\n",
       " [29, 305, 306, 307, 38, 17, 10, 308],\n",
       " [29, 305, 306, 307, 38, 17, 10, 308, 309],\n",
       " [55, 310],\n",
       " [55, 310, 138],\n",
       " [55, 310, 138, 38],\n",
       " [55, 310, 138, 38, 17],\n",
       " [55, 310, 138, 38, 17, 79],\n",
       " [55, 310, 138, 38, 17, 79, 16],\n",
       " [55, 310, 138, 38, 17, 79, 16, 311],\n",
       " [55, 310, 138, 38, 17, 79, 16, 311, 138],\n",
       " [55, 310, 138, 38, 17, 79, 16, 311, 138, 10],\n",
       " [55, 310, 138, 38, 17, 79, 16, 311, 138, 10, 312],\n",
       " [55, 310, 138, 38, 17, 79, 16, 311, 138, 10, 312, 6],\n",
       " [55, 310, 138, 38, 17, 79, 16, 311, 138, 10, 312, 6, 10],\n",
       " [55, 310, 138, 38, 17, 79, 16, 311, 138, 10, 312, 6, 10, 313],\n",
       " [139, 314],\n",
       " [139, 314, 3],\n",
       " [139, 314, 3, 10],\n",
       " [139, 314, 3, 10, 13],\n",
       " [139, 314, 3, 10, 13, 315],\n",
       " [139, 314, 3, 10, 13, 315, 8],\n",
       " [139, 314, 3, 10, 13, 315, 8, 9],\n",
       " [139, 314, 3, 10, 13, 315, 8, 9, 140],\n",
       " [139, 314, 3, 10, 13, 315, 8, 9, 140, 6],\n",
       " [139, 314, 3, 10, 13, 315, 8, 9, 140, 6, 316],\n",
       " [139, 314, 3, 10, 13, 315, 8, 9, 140, 6, 316, 68],\n",
       " [139, 314, 3, 10, 13, 315, 8, 9, 140, 6, 316, 68, 105],\n",
       " [139, 314, 3, 10, 13, 315, 8, 9, 140, 6, 316, 68, 105, 317],\n",
       " [139, 314, 3, 10, 13, 315, 8, 9, 140, 6, 316, 68, 105, 317, 318],\n",
       " [13, 18],\n",
       " [13, 18, 8],\n",
       " [13, 18, 8, 2],\n",
       " [13, 18, 8, 2, 319],\n",
       " [6, 32],\n",
       " [6, 32, 320],\n",
       " [15, 29],\n",
       " [15, 29, 5],\n",
       " [15, 29, 5, 93],\n",
       " [15, 29, 5, 93, 141],\n",
       " [142, 15],\n",
       " [142, 15, 321],\n",
       " [142, 15, 321, 5],\n",
       " [142, 15, 321, 5, 143],\n",
       " [142, 15, 321, 5, 143, 136],\n",
       " [142, 15, 321, 5, 143, 136, 141],\n",
       " [142, 15, 321, 5, 143, 136, 141, 1],\n",
       " [142, 15, 321, 5, 143, 136, 141, 1, 322],\n",
       " [142, 15, 321, 5, 143, 136, 141, 1, 322, 9],\n",
       " [142, 15, 321, 5, 143, 136, 141, 1, 322, 9, 2],\n",
       " [142, 15, 321, 5, 143, 136, 141, 1, 322, 9, 2, 20],\n",
       " [142, 15, 321, 5, 143, 136, 141, 1, 322, 9, 2, 20, 5],\n",
       " [142, 15, 321, 5, 143, 136, 141, 1, 322, 9, 2, 20, 5, 143],\n",
       " [142, 15, 321, 5, 143, 136, 141, 1, 322, 9, 2, 20, 5, 143, 36],\n",
       " [142, 15, 321, 5, 143, 136, 141, 1, 322, 9, 2, 20, 5, 143, 36, 2],\n",
       " [142, 15, 321, 5, 143, 136, 141, 1, 322, 9, 2, 20, 5, 143, 36, 2, 5],\n",
       " [142, 15, 321, 5, 143, 136, 141, 1, 322, 9, 2, 20, 5, 143, 36, 2, 5, 323],\n",
       " [142,\n",
       "  15,\n",
       "  321,\n",
       "  5,\n",
       "  143,\n",
       "  136,\n",
       "  141,\n",
       "  1,\n",
       "  322,\n",
       "  9,\n",
       "  2,\n",
       "  20,\n",
       "  5,\n",
       "  143,\n",
       "  36,\n",
       "  2,\n",
       "  5,\n",
       "  323,\n",
       "  144],\n",
       " [142,\n",
       "  15,\n",
       "  321,\n",
       "  5,\n",
       "  143,\n",
       "  136,\n",
       "  141,\n",
       "  1,\n",
       "  322,\n",
       "  9,\n",
       "  2,\n",
       "  20,\n",
       "  5,\n",
       "  143,\n",
       "  36,\n",
       "  2,\n",
       "  5,\n",
       "  323,\n",
       "  144,\n",
       "  13],\n",
       " [142,\n",
       "  15,\n",
       "  321,\n",
       "  5,\n",
       "  143,\n",
       "  136,\n",
       "  141,\n",
       "  1,\n",
       "  322,\n",
       "  9,\n",
       "  2,\n",
       "  20,\n",
       "  5,\n",
       "  143,\n",
       "  36,\n",
       "  2,\n",
       "  5,\n",
       "  323,\n",
       "  144,\n",
       "  13,\n",
       "  36],\n",
       " [9, 324],\n",
       " [9, 324, 2],\n",
       " [9, 324, 2, 20],\n",
       " [9, 324, 2, 20, 50],\n",
       " [9, 324, 2, 20, 50, 144],\n",
       " [9, 324, 2, 20, 50, 144, 34],\n",
       " [9, 324, 2, 20, 50, 144, 34, 12],\n",
       " [9, 324, 2, 20, 50, 144, 34, 12, 325],\n",
       " [9, 324, 2, 20, 50, 144, 34, 12, 325, 32],\n",
       " [9, 324, 2, 20, 50, 144, 34, 12, 325, 32, 326],\n",
       " [9, 324, 2, 20, 50, 144, 34, 12, 325, 32, 326, 14],\n",
       " [9, 324, 2, 20, 50, 144, 34, 12, 325, 32, 326, 14, 20],\n",
       " [9, 324, 2, 20, 50, 144, 34, 12, 325, 32, 326, 14, 20, 1],\n",
       " [9, 324, 2, 20, 50, 144, 34, 12, 325, 32, 326, 14, 20, 1, 8],\n",
       " [9, 324, 2, 20, 50, 144, 34, 12, 325, 32, 326, 14, 20, 1, 8, 6],\n",
       " [9, 324, 2, 20, 50, 144, 34, 12, 325, 32, 326, 14, 20, 1, 8, 6, 327],\n",
       " [9, 324, 2, 20, 50, 144, 34, 12, 325, 32, 326, 14, 20, 1, 8, 6, 327, 1],\n",
       " [9, 324, 2, 20, 50, 144, 34, 12, 325, 32, 326, 14, 20, 1, 8, 6, 327, 1, 8],\n",
       " [58, 24],\n",
       " [58, 24, 145],\n",
       " [58, 24, 145, 7],\n",
       " [58, 24, 145, 7, 58],\n",
       " [58, 24, 145, 7, 58, 53],\n",
       " [58, 24, 145, 7, 58, 53, 328],\n",
       " [58, 24, 145, 7, 58, 53, 328, 146],\n",
       " [58, 24, 145, 7, 58, 53, 328, 146, 2],\n",
       " [58, 24, 145, 7, 58, 53, 328, 146, 2, 20],\n",
       " [58, 24, 145, 7, 58, 53, 328, 146, 2, 20, 1],\n",
       " [58, 24, 145, 7, 58, 53, 328, 146, 2, 20, 1, 8],\n",
       " [58, 24, 145, 7, 58, 53, 328, 146, 2, 20, 1, 8, 329],\n",
       " [58, 24, 145, 7, 58, 53, 328, 146, 2, 20, 1, 8, 329, 330],\n",
       " [58, 24, 145, 7, 58, 53, 328, 146, 2, 20, 1, 8, 329, 330, 11],\n",
       " [58, 24, 145, 7, 58, 53, 328, 146, 2, 20, 1, 8, 329, 330, 11, 3],\n",
       " [58, 24, 145, 7, 58, 53, 328, 146, 2, 20, 1, 8, 329, 330, 11, 3, 147],\n",
       " [14, 7],\n",
       " [14, 7, 80],\n",
       " [14, 7, 80, 94],\n",
       " [14, 7, 80, 94, 148],\n",
       " [15, 31],\n",
       " [15, 31, 40],\n",
       " [15, 31, 40, 7],\n",
       " [15, 31, 40, 7, 149],\n",
       " [15, 31, 40, 7, 149, 1],\n",
       " [15, 31, 40, 7, 149, 1, 19],\n",
       " [15, 31, 40, 7, 149, 1, 19, 7],\n",
       " [15, 31, 40, 7, 149, 1, 19, 7, 20],\n",
       " [15, 31, 40, 7, 149, 1, 19, 7, 20, 16],\n",
       " [15, 31, 40, 7, 149, 1, 19, 7, 20, 16, 1],\n",
       " [15, 31, 40, 7, 149, 1, 19, 7, 20, 16, 1, 21],\n",
       " [15, 31, 40, 7, 149, 1, 19, 7, 20, 16, 1, 21, 10],\n",
       " [15, 31, 40, 7, 149, 1, 19, 7, 20, 16, 1, 21, 10, 142],\n",
       " [15, 31, 40, 7, 149, 1, 19, 7, 20, 16, 1, 21, 10, 142, 15],\n",
       " [15, 31, 40, 7, 149, 1, 19, 7, 20, 16, 1, 21, 10, 142, 15, 31],\n",
       " [15, 31, 40, 7, 149, 1, 19, 7, 20, 16, 1, 21, 10, 142, 15, 31, 40],\n",
       " [15, 31, 40, 7, 149, 1, 19, 7, 20, 16, 1, 21, 10, 142, 15, 31, 40, 7],\n",
       " [15, 31, 40, 7, 149, 1, 19, 7, 20, 16, 1, 21, 10, 142, 15, 31, 40, 7, 149],\n",
       " [1, 36],\n",
       " [1, 36, 88],\n",
       " [1, 36, 88, 7],\n",
       " [1, 36, 88, 7, 67],\n",
       " [1, 36, 88, 7, 67, 2],\n",
       " [1, 36, 88, 7, 67, 2, 331],\n",
       " [1, 36, 88, 7, 67, 2, 331, 1],\n",
       " [1, 36, 88, 7, 67, 2, 331, 1, 8],\n",
       " [1, 36, 88, 7, 67, 2, 331, 1, 8, 28],\n",
       " [1, 36, 88, 7, 67, 2, 331, 1, 8, 28, 5],\n",
       " [1, 36, 88, 7, 67, 2, 331, 1, 8, 28, 5, 332],\n",
       " [1, 36, 88, 7, 67, 2, 331, 1, 8, 28, 5, 332, 150],\n",
       " [1, 36, 88, 7, 67, 2, 331, 1, 8, 28, 5, 332, 150, 5],\n",
       " [1, 36, 88, 7, 67, 2, 331, 1, 8, 28, 5, 332, 150, 5, 333],\n",
       " [1, 36, 88, 7, 67, 2, 331, 1, 8, 28, 5, 332, 150, 5, 333, 22],\n",
       " [1, 36, 88, 7, 67, 2, 331, 1, 8, 28, 5, 332, 150, 5, 333, 22, 5],\n",
       " [334, 36],\n",
       " [29, 335],\n",
       " [29, 335, 336],\n",
       " [29, 335, 336, 27],\n",
       " [29, 335, 336, 27, 33],\n",
       " [29, 335, 336, 27, 33, 337],\n",
       " [29, 335, 336, 27, 33, 337, 150],\n",
       " [29, 335, 336, 27, 33, 337, 150, 40],\n",
       " [29, 335, 336, 27, 33, 337, 150, 40, 7],\n",
       " [29, 335, 336, 27, 33, 337, 150, 40, 7, 83],\n",
       " [29, 335, 336, 27, 33, 337, 150, 40, 7, 83, 2],\n",
       " [29, 335, 336, 27, 33, 337, 150, 40, 7, 83, 2, 338],\n",
       " [29, 335, 336, 27, 33, 337, 150, 40, 7, 83, 2, 338, 1],\n",
       " [29, 335, 336, 27, 33, 337, 150, 40, 7, 83, 2, 338, 1, 151],\n",
       " [29, 335, 336, 27, 33, 337, 150, 40, 7, 83, 2, 338, 1, 151, 4],\n",
       " [29, 335, 336, 27, 33, 337, 150, 40, 7, 83, 2, 338, 1, 151, 4, 1],\n",
       " [29, 335, 336, 27, 33, 337, 150, 40, 7, 83, 2, 338, 1, 151, 4, 1, 20],\n",
       " [29, 335, 336, 27, 33, 337, 150, 40, 7, 83, 2, 338, 1, 151, 4, 1, 20, 16],\n",
       " [29, 335, 336, 27, 33, 337, 150, 40, 7, 83, 2, 338, 1, 151, 4, 1, 20, 16, 21],\n",
       " [59, 339],\n",
       " [59, 339, 5],\n",
       " [59, 339, 5, 36],\n",
       " [59, 339, 5, 36, 2],\n",
       " [59, 339, 5, 36, 2, 145],\n",
       " [59, 339, 5, 36, 2, 145, 8],\n",
       " [59, 339, 5, 36, 2, 145, 8, 23],\n",
       " [59, 339, 5, 36, 2, 145, 8, 23, 9],\n",
       " [59, 339, 5, 36, 2, 145, 8, 23, 9, 133],\n",
       " [59, 339, 5, 36, 2, 145, 8, 23, 9, 133, 2],\n",
       " [59, 339, 5, 36, 2, 145, 8, 23, 9, 133, 2, 340],\n",
       " [59, 339, 5, 36, 2, 145, 8, 23, 9, 133, 2, 340, 1],\n",
       " [59, 339, 5, 36, 2, 145, 8, 23, 9, 133, 2, 340, 1, 151],\n",
       " [59, 339, 5, 36, 2, 145, 8, 23, 9, 133, 2, 340, 1, 151, 4],\n",
       " [59, 339, 5, 36, 2, 145, 8, 23, 9, 133, 2, 340, 1, 151, 4, 1],\n",
       " [59, 339, 5, 36, 2, 145, 8, 23, 9, 133, 2, 340, 1, 151, 4, 1, 20],\n",
       " [59, 339, 5, 36, 2, 145, 8, 23, 9, 133, 2, 340, 1, 151, 4, 1, 20, 10],\n",
       " [59, 339, 5, 36, 2, 145, 8, 23, 9, 133, 2, 340, 1, 151, 4, 1, 20, 10, 341],\n",
       " [59, 339, 5, 36, 2, 145, 8, 23, 9, 133, 2, 340, 1, 151, 4, 1, 20, 10, 341, 4],\n",
       " [1, 152],\n",
       " [1, 152, 153],\n",
       " [1, 152, 153, 46],\n",
       " [1, 152, 153, 46, 1],\n",
       " [1, 152, 153, 46, 1, 8],\n",
       " [1, 152, 153, 46, 1, 8, 7],\n",
       " [1, 152, 153, 46, 1, 8, 7, 12],\n",
       " [1, 152, 153, 46, 1, 8, 7, 12, 82],\n",
       " [1, 152, 153, 46, 1, 8, 7, 12, 82, 6],\n",
       " [1, 152, 153, 46, 1, 8, 7, 12, 82, 6, 1],\n",
       " [1, 152, 153, 46, 1, 8, 7, 12, 82, 6, 1, 342],\n",
       " [1, 152, 153, 46, 1, 8, 7, 12, 82, 6, 1, 342, 36],\n",
       " [1, 152, 153, 46, 1, 8, 7, 12, 82, 6, 1, 342, 36, 59],\n",
       " [1, 152, 153, 46, 1, 8, 7, 12, 82, 6, 1, 342, 36, 59, 343],\n",
       " [1, 152, 153, 46, 1, 8, 7, 12, 82, 6, 1, 342, 36, 59, 343, 1],\n",
       " [152, 153],\n",
       " [152, 153, 1],\n",
       " [152, 153, 1, 96],\n",
       " [152, 153, 1, 96, 20],\n",
       " [152, 153, 1, 96, 20, 9],\n",
       " [152, 153, 1, 96, 20, 9, 344],\n",
       " [152, 153, 1, 96, 20, 9, 344, 345],\n",
       " [152, 153, 1, 96, 20, 9, 344, 345, 5],\n",
       " [152, 153, 1, 96, 20, 9, 344, 345, 5, 346],\n",
       " [152, 153, 1, 96, 20, 9, 344, 345, 5, 346, 347],\n",
       " [152, 153, 1, 96, 20, 9, 344, 345, 5, 346, 347, 348],\n",
       " [123, 124],\n",
       " [125, 126],\n",
       " [125, 126, 127],\n",
       " [125, 126, 127, 6],\n",
       " [125, 126, 127, 6, 128],\n",
       " [125, 126, 127, 6, 128, 129],\n",
       " [125, 126, 127, 6, 128, 129, 29],\n",
       " [57, 130],\n",
       " [57, 130, 57],\n",
       " [57, 130, 57, 131],\n",
       " [57, 130, 57, 131, 61],\n",
       " [57, 130, 57, 131, 61, 2],\n",
       " [57, 130, 57, 131, 61, 2, 11],\n",
       " [57, 130, 57, 131, 61, 2, 11, 3],\n",
       " [55, 30],\n",
       " [55, 30, 43],\n",
       " [55, 30, 43, 4],\n",
       " [55, 30, 43, 4, 154],\n",
       " [55, 30, 43, 4, 154, 6],\n",
       " [55, 30, 43, 4, 154, 6, 30],\n",
       " [55, 30, 43, 4, 154, 6, 30, 19],\n",
       " [55, 30, 43, 4, 154, 6, 30, 19, 349],\n",
       " [55, 30, 43, 4, 154, 6, 30, 19, 349, 39],\n",
       " [55, 30, 43, 4, 154, 6, 30, 19, 349, 39, 24],\n",
       " [55, 30, 43, 4, 154, 6, 30, 19, 349, 39, 24, 350],\n",
       " [55, 30, 43, 4, 154, 6, 30, 19, 349, 39, 24, 350, 140],\n",
       " [55, 30, 43, 4, 154, 6, 30, 19, 349, 39, 24, 350, 140, 2],\n",
       " [55, 30, 43, 4, 154, 6, 30, 19, 349, 39, 24, 350, 140, 2, 351],\n",
       " [55, 30, 43, 4, 154, 6, 30, 19, 349, 39, 24, 350, 140, 2, 351, 26],\n",
       " [31, 352],\n",
       " [31, 352, 12],\n",
       " [31, 352, 12, 7],\n",
       " [31, 352, 12, 7, 353],\n",
       " [31, 352, 12, 7, 353, 2],\n",
       " [31, 352, 12, 7, 353, 2, 354],\n",
       " [31, 352, 12, 7, 353, 2, 354, 16],\n",
       " [31, 352, 12, 7, 353, 2, 354, 16, 5],\n",
       " [31, 352, 12, 7, 353, 2, 354, 16, 5, 104],\n",
       " [31, 352, 12, 7, 353, 2, 354, 16, 5, 104, 22],\n",
       " [31, 352, 12, 7, 353, 2, 354, 16, 5, 104, 22, 39],\n",
       " [31, 352, 12, 7, 353, 2, 354, 16, 5, 104, 22, 39, 7],\n",
       " [31, 352, 12, 7, 353, 2, 354, 16, 5, 104, 22, 39, 7, 83],\n",
       " [31, 352, 12, 7, 353, 2, 354, 16, 5, 104, 22, 39, 7, 83, 355],\n",
       " [31, 352, 12, 7, 353, 2, 354, 16, 5, 104, 22, 39, 7, 83, 355, 22],\n",
       " [31, 352, 12, 7, 353, 2, 354, 16, 5, 104, 22, 39, 7, 83, 355, 22, 356],\n",
       " [139, 357],\n",
       " [139, 357, 7],\n",
       " [139, 357, 7, 146],\n",
       " [139, 357, 7, 146, 2],\n",
       " [139, 357, 7, 146, 2, 358],\n",
       " [139, 357, 7, 146, 2, 358, 5],\n",
       " [139, 357, 7, 146, 2, 358, 5, 19],\n",
       " [139, 357, 7, 146, 2, 358, 5, 19, 14],\n",
       " [139, 357, 7, 146, 2, 358, 5, 19, 14, 99],\n",
       " [139, 357, 7, 146, 2, 358, 5, 19, 14, 99, 70],\n",
       " [139, 357, 7, 146, 2, 358, 5, 19, 14, 99, 70, 359],\n",
       " [139, 357, 7, 146, 2, 358, 5, 19, 14, 99, 70, 359, 155],\n",
       " [139, 357, 7, 146, 2, 358, 5, 19, 14, 99, 70, 359, 155, 10],\n",
       " [139, 357, 7, 146, 2, 358, 5, 19, 14, 99, 70, 359, 155, 10, 156],\n",
       " [139, 357, 7, 146, 2, 358, 5, 19, 14, 99, 70, 359, 155, 10, 156, 360],\n",
       " [139, 357, 7, 146, 2, 358, 5, 19, 14, 99, 70, 359, 155, 10, 156, 360, 14],\n",
       " [9, 361],\n",
       " [9, 361, 7],\n",
       " [9, 361, 7, 58],\n",
       " [9, 361, 7, 58, 42],\n",
       " [9, 361, 7, 58, 42, 5],\n",
       " [9, 361, 7, 58, 42, 5, 19],\n",
       " [9, 361, 7, 58, 42, 5, 19, 69],\n",
       " [9, 361, 7, 58, 42, 5, 19, 69, 18],\n",
       " [9, 361, 7, 58, 42, 5, 19, 69, 18, 8],\n",
       " [9, 361, 7, 58, 42, 5, 19, 69, 18, 8, 7],\n",
       " [9, 361, 7, 58, 42, 5, 19, 69, 18, 8, 7, 362],\n",
       " [9, 361, 7, 58, 42, 5, 19, 69, 18, 8, 7, 362, 363],\n",
       " [9, 361, 7, 58, 42, 5, 19, 69, 18, 8, 7, 362, 363, 119],\n",
       " [9, 361, 7, 58, 42, 5, 19, 69, 18, 8, 7, 362, 363, 119, 31],\n",
       " [9, 361, 7, 58, 42, 5, 19, 69, 18, 8, 7, 362, 363, 119, 31, 26],\n",
       " [23, 364],\n",
       " [23, 364, 60],\n",
       " [23, 364, 60, 156],\n",
       " [23, 364, 60, 156, 35],\n",
       " [23, 364, 60, 156, 35, 8],\n",
       " [23, 364, 60, 156, 35, 8, 59],\n",
       " [23, 364, 60, 156, 35, 8, 59, 5],\n",
       " [23, 364, 60, 156, 35, 8, 59, 5, 19],\n",
       " [23, 364, 60, 156, 35, 8, 59, 5, 19, 365],\n",
       " [23, 364, 60, 156, 35, 8, 59, 5, 19, 365, 18],\n",
       " [23, 364, 60, 156, 35, 8, 59, 5, 19, 365, 18, 8],\n",
       " [23, 364, 60, 156, 35, 8, 59, 5, 19, 365, 18, 8, 26],\n",
       " [23, 364, 60, 156, 35, 8, 59, 5, 19, 365, 18, 8, 26, 157],\n",
       " [23, 364, 60, 156, 35, 8, 59, 5, 19, 365, 18, 8, 26, 157, 366],\n",
       " [23, 364, 60, 156, 35, 8, 59, 5, 19, 365, 18, 8, 26, 157, 366, 367],\n",
       " [23, 364, 60, 156, 35, 8, 59, 5, 19, 365, 18, 8, 26, 157, 366, 367, 60],\n",
       " [35, 8],\n",
       " [35, 8, 7],\n",
       " [35, 8, 7, 158],\n",
       " [35, 8, 7, 158, 14],\n",
       " [35, 8, 7, 158, 14, 1],\n",
       " [35, 8, 7, 158, 14, 1, 19],\n",
       " [35, 8, 7, 158, 14, 1, 19, 41],\n",
       " [35, 8, 7, 158, 14, 1, 19, 41, 368],\n",
       " [35, 8, 7, 158, 14, 1, 19, 41, 368, 1],\n",
       " [35, 8, 7, 158, 14, 1, 19, 41, 368, 1, 18],\n",
       " [35, 8, 7, 158, 14, 1, 19, 41, 368, 1, 18, 8],\n",
       " [35, 8, 7, 158, 14, 1, 19, 41, 368, 1, 18, 8, 369],\n",
       " [35, 8, 7, 158, 14, 1, 19, 41, 368, 1, 18, 8, 369, 27],\n",
       " [35, 8, 7, 158, 14, 1, 19, 41, 368, 1, 18, 8, 369, 27, 1],\n",
       " [35, 8, 7, 158, 14, 1, 19, 41, 368, 1, 18, 8, 369, 27, 1, 19],\n",
       " [35, 8, 7, 158, 14, 1, 19, 41, 368, 1, 18, 8, 369, 27, 1, 19, 41],\n",
       " [35, 8, 7, 158, 14, 1, 19, 41, 368, 1, 18, 8, 369, 27, 1, 19, 41, 20],\n",
       " [35, 8, 7, 158, 14, 1, 19, 41, 368, 1, 18, 8, 369, 27, 1, 19, 41, 20, 159],\n",
       " [4, 1],\n",
       " [4, 1, 370],\n",
       " [4, 1, 370, 14],\n",
       " [4, 1, 370, 14, 12],\n",
       " [4, 1, 370, 14, 12, 53],\n",
       " [4, 1, 370, 14, 12, 53, 371],\n",
       " [4, 1, 370, 14, 12, 53, 371, 372],\n",
       " [4, 1, 370, 14, 12, 53, 371, 372, 2],\n",
       " [4, 1, 370, 14, 12, 53, 371, 372, 2, 1],\n",
       " [4, 1, 370, 14, 12, 53, 371, 372, 2, 1, 103],\n",
       " [4, 1, 370, 14, 12, 53, 371, 372, 2, 1, 103, 373],\n",
       " [4, 1, 370, 14, 12, 53, 371, 372, 2, 1, 103, 373, 374],\n",
       " [4, 1, 370, 14, 12, 53, 371, 372, 2, 1, 103, 373, 374, 27],\n",
       " [4, 1, 370, 14, 12, 53, 371, 372, 2, 1, 103, 373, 374, 27, 33],\n",
       " [4, 1, 370, 14, 12, 53, 371, 372, 2, 1, 103, 373, 374, 27, 33, 375],\n",
       " [4, 1, 370, 14, 12, 53, 371, 372, 2, 1, 103, 373, 374, 27, 33, 375, 15],\n",
       " [4, 1, 370, 14, 12, 53, 371, 372, 2, 1, 103, 373, 374, 27, 33, 375, 15, 376],\n",
       " [4,\n",
       "  1,\n",
       "  370,\n",
       "  14,\n",
       "  12,\n",
       "  53,\n",
       "  371,\n",
       "  372,\n",
       "  2,\n",
       "  1,\n",
       "  103,\n",
       "  373,\n",
       "  374,\n",
       "  27,\n",
       "  33,\n",
       "  375,\n",
       "  15,\n",
       "  376,\n",
       "  377],\n",
       " [4,\n",
       "  1,\n",
       "  370,\n",
       "  14,\n",
       "  12,\n",
       "  53,\n",
       "  371,\n",
       "  372,\n",
       "  2,\n",
       "  1,\n",
       "  103,\n",
       "  373,\n",
       "  374,\n",
       "  27,\n",
       "  33,\n",
       "  375,\n",
       "  15,\n",
       "  376,\n",
       "  377,\n",
       "  6],\n",
       " [378, 379],\n",
       " [378, 379, 38],\n",
       " [378, 379, 38, 159],\n",
       " [378, 379, 38, 159, 12],\n",
       " [378, 379, 38, 159, 12, 380],\n",
       " [378, 379, 38, 159, 12, 380, 2],\n",
       " [378, 379, 38, 159, 12, 380, 2, 17],\n",
       " [378, 379, 38, 159, 12, 380, 2, 17, 381],\n",
       " [378, 379, 38, 159, 12, 380, 2, 17, 381, 59],\n",
       " [378, 379, 38, 159, 12, 380, 2, 17, 381, 59, 382],\n",
       " [378, 379, 38, 159, 12, 380, 2, 17, 381, 59, 382, 383],\n",
       " [378, 379, 38, 159, 12, 380, 2, 17, 381, 59, 382, 383, 7],\n",
       " [378, 379, 38, 159, 12, 380, 2, 17, 381, 59, 382, 383, 7, 158],\n",
       " [378, 379, 38, 159, 12, 380, 2, 17, 381, 59, 382, 383, 7, 158, 14],\n",
       " [378, 379, 38, 159, 12, 380, 2, 17, 381, 59, 382, 383, 7, 158, 14, 1],\n",
       " [19, 384],\n",
       " [19, 384, 53],\n",
       " [19, 384, 53, 385],\n",
       " [19, 384, 53, 385, 26],\n",
       " [19, 384, 53, 385, 26, 2],\n",
       " [19, 384, 53, 385, 26, 2, 1],\n",
       " [19, 384, 53, 385, 26, 2, 1, 35],\n",
       " [19, 384, 53, 385, 26, 2, 1, 35, 8],\n",
       " [19, 384, 53, 385, 26, 2, 1, 35, 8, 386],\n",
       " [19, 384, 53, 385, 26, 2, 1, 35, 8, 386, 23],\n",
       " [19, 384, 53, 385, 26, 2, 1, 35, 8, 386, 23, 387],\n",
       " [19, 384, 53, 385, 26, 2, 1, 35, 8, 386, 23, 387, 155],\n",
       " [19, 384, 53, 385, 26, 2, 1, 35, 8, 386, 23, 387, 155, 60],\n",
       " [19, 384, 53, 385, 26, 2, 1, 35, 8, 386, 23, 387, 155, 60, 1],\n",
       " [19, 384, 53, 385, 26, 2, 1, 35, 8, 386, 23, 387, 155, 60, 1, 35],\n",
       " [8, 14],\n",
       " [8, 14, 12],\n",
       " [8, 14, 12, 388],\n",
       " [8, 14, 12, 388, 389],\n",
       " [8, 14, 12, 388, 389, 390],\n",
       " [8, 14, 12, 388, 389, 390, 54],\n",
       " [8, 14, 12, 388, 389, 390, 54, 84],\n",
       " [8, 14, 12, 388, 389, 390, 54, 84, 58],\n",
       " [8, 14, 12, 388, 389, 390, 54, 84, 58, 71],\n",
       " [8, 14, 12, 388, 389, 390, 54, 84, 58, 71, 391],\n",
       " [8, 14, 12, 388, 389, 390, 54, 84, 58, 71, 391, 16],\n",
       " [8, 14, 12, 388, 389, 390, 54, 84, 58, 71, 391, 16, 82],\n",
       " [8, 14, 12, 388, 389, 390, 54, 84, 58, 71, 391, 16, 82, 1],\n",
       " [8, 14, 12, 388, 389, 390, 54, 84, 58, 71, 391, 16, 82, 1, 20],\n",
       " [8, 14, 12, 388, 389, 390, 54, 84, 58, 71, 391, 16, 82, 1, 20, 2],\n",
       " [8, 14, 12, 388, 389, 390, 54, 84, 58, 71, 391, 16, 82, 1, 20, 2, 1],\n",
       " [8, 14, 12, 388, 389, 390, 54, 84, 58, 71, 391, 16, 82, 1, 20, 2, 1, 18],\n",
       " [11, 3],\n",
       " [11, 3, 392],\n",
       " [11, 3, 392, 5],\n",
       " [11, 3, 392, 5, 393],\n",
       " [11, 3, 392, 5, 393, 394],\n",
       " [11, 3, 392, 5, 393, 394, 4],\n",
       " [11, 3, 392, 5, 393, 394, 4, 395],\n",
       " [11, 3, 392, 5, 393, 394, 4, 395, 45],\n",
       " [11, 3, 392, 5, 393, 394, 4, 395, 45, 13],\n",
       " [11, 3, 392, 5, 393, 394, 4, 395, 45, 13, 2],\n",
       " [11, 3, 392, 5, 393, 394, 4, 395, 45, 13, 2, 396],\n",
       " [11, 3, 392, 5, 393, 394, 4, 395, 45, 13, 2, 396, 50],\n",
       " [11, 3, 392, 5, 393, 394, 4, 395, 45, 13, 2, 396, 50, 397],\n",
       " [398, 28],\n",
       " [398, 28, 1],\n",
       " [398, 28, 1, 115],\n",
       " [398, 28, 1, 115, 399],\n",
       " [398, 28, 1, 115, 399, 4],\n",
       " [398, 28, 1, 115, 399, 4, 1],\n",
       " [398, 28, 1, 115, 399, 4, 1, 400],\n",
       " [398, 28, 1, 115, 399, 4, 1, 400, 17],\n",
       " [398, 28, 1, 115, 399, 4, 1, 400, 17, 2],\n",
       " [398, 28, 1, 115, 399, 4, 1, 400, 17, 2, 13],\n",
       " [398, 28, 1, 115, 399, 4, 1, 400, 17, 2, 13, 77],\n",
       " [398, 28, 1, 115, 399, 4, 1, 400, 17, 2, 13, 77, 401],\n",
       " [398, 28, 1, 115, 399, 4, 1, 400, 17, 2, 13, 77, 401, 2],\n",
       " [398, 28, 1, 115, 399, 4, 1, 400, 17, 2, 13, 77, 401, 2, 24],\n",
       " [398, 28, 1, 115, 399, 4, 1, 400, 17, 2, 13, 77, 401, 2, 24, 402],\n",
       " [398, 28, 1, 115, 399, 4, 1, 400, 17, 2, 13, 77, 401, 2, 24, 402, 60],\n",
       " [5, 403],\n",
       " [5, 403, 404],\n",
       " [5, 403, 404, 4],\n",
       " [5, 403, 404, 4, 8],\n",
       " [5, 403, 404, 4, 8, 62],\n",
       " [5, 403, 404, 4, 8, 62, 30],\n",
       " [5, 403, 404, 4, 8, 62, 30, 116],\n",
       " [5, 403, 404, 4, 8, 62, 30, 116, 405],\n",
       " [5, 403, 404, 4, 8, 62, 30, 116, 405, 77],\n",
       " [5, 403, 404, 4, 8, 62, 30, 116, 405, 77, 70],\n",
       " [5, 403, 404, 4, 8, 62, 30, 116, 405, 77, 70, 72],\n",
       " [5, 403, 404, 4, 8, 62, 30, 116, 405, 77, 70, 72, 4],\n",
       " [5, 403, 404, 4, 8, 62, 30, 116, 405, 77, 70, 72, 4, 406],\n",
       " [5, 403, 404, 4, 8, 62, 30, 116, 405, 77, 70, 72, 4, 406, 30],\n",
       " [4, 50],\n",
       " [4, 50, 148],\n",
       " [4, 50, 148, 38],\n",
       " [4, 50, 148, 38, 17],\n",
       " [4, 50, 148, 38, 17, 107],\n",
       " [4, 50, 148, 38, 17, 107, 407],\n",
       " [4, 50, 148, 38, 17, 107, 407, 46],\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ab4c28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len=max([len(x) for x in inp_seq])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dc4a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_inp_seq=pad_sequences(inp_seq ,maxlen=max_len,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23101c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,  15,  61],\n",
       "       [  0,   0,   0, ...,  15,  61,   2],\n",
       "       [  0,   0,   0, ...,  61,   2,  11],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  84,  39,  40],\n",
       "       [  0,   0,   0, ...,  39,  40, 425],\n",
       "       [  0,   0,   0, ...,  40, 425, 426]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_inp_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e48674cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=padded_inp_seq[:,:-1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2770130b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,  15],\n",
       "       [  0,   0,   0, ...,   0,  15,  61],\n",
       "       [  0,   0,   0, ...,  15,  61,   2],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   3,  84,  39],\n",
       "       [  0,   0,   0, ...,  84,  39,  40],\n",
       "       [  0,   0,   0, ...,  39,  40, 425]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bd24d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3773c4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1056, 20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acf53024",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=padded_inp_seq[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa9ed540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 61,   2,  11, ...,  40, 425, 426])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8a6cb27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1056"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85d82ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1056,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b045d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding on y\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y=to_categorical(y,num_classes=427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b587b073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1056, 427)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd373873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fd1285a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "427"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d06ec163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be557acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48241dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(427,100,input_length=20))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(427,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35247686",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37f2de0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 20, 100)           42700     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 150)               150600    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 427)               64477     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 257,777\n",
      "Trainable params: 257,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33f81ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "33/33 [==============================] - 3s 28ms/step - loss: 5.8642 - accuracy: 0.0388\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 5.4632 - accuracy: 0.0511\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 5.3870 - accuracy: 0.0407\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 5.3537 - accuracy: 0.0511\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 5.3135 - accuracy: 0.0511\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 5.2429 - accuracy: 0.0653\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 5.1472 - accuracy: 0.0739\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 5.0235 - accuracy: 0.0852\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 4.8660 - accuracy: 0.1297\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 4.6832 - accuracy: 0.1496\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 4.4724 - accuracy: 0.1562\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 4.2526 - accuracy: 0.1932\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 4.0233 - accuracy: 0.2064\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 3.7894 - accuracy: 0.2367\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 3.5731 - accuracy: 0.2652\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 3.3597 - accuracy: 0.2936\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 3.1426 - accuracy: 0.3400\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 2.9547 - accuracy: 0.3722\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 2.7632 - accuracy: 0.4233\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 2.5869 - accuracy: 0.4536\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 2.4099 - accuracy: 0.4991\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 2.2507 - accuracy: 0.5436\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 2.0923 - accuracy: 0.5871\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 1.9470 - accuracy: 0.6316\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 1.8073 - accuracy: 0.6705\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 1.6743 - accuracy: 0.7055\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 1.5480 - accuracy: 0.7585\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 1.4337 - accuracy: 0.7831\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 1.3215 - accuracy: 0.8068\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 1.2258 - accuracy: 0.8305\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 1.1361 - accuracy: 0.8475\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 1.0496 - accuracy: 0.8674\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.9704 - accuracy: 0.8807\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.8924 - accuracy: 0.9006\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.8242 - accuracy: 0.9100\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 0.7637 - accuracy: 0.9176\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 0.7082 - accuracy: 0.9318\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 0.6591 - accuracy: 0.9271\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.6142 - accuracy: 0.9413\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.5736 - accuracy: 0.9441\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.5349 - accuracy: 0.9451\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.5010 - accuracy: 0.9470\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.4695 - accuracy: 0.9470\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 0.4429 - accuracy: 0.9517\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 0.4171 - accuracy: 0.9555\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.3931 - accuracy: 0.9498\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 0.3700 - accuracy: 0.9555\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.3496 - accuracy: 0.9527\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.3316 - accuracy: 0.9564\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.3152 - accuracy: 0.9564\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2982 - accuracy: 0.9583\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2857 - accuracy: 0.9555\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2744 - accuracy: 0.9602\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2604 - accuracy: 0.9583\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2502 - accuracy: 0.9602\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2389 - accuracy: 0.9574\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2308 - accuracy: 0.9640\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2215 - accuracy: 0.9583\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2136 - accuracy: 0.9612\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.2060 - accuracy: 0.9602\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1993 - accuracy: 0.9640\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1923 - accuracy: 0.9602\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1852 - accuracy: 0.9621\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1810 - accuracy: 0.9640\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1749 - accuracy: 0.9602\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1706 - accuracy: 0.9583\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1648 - accuracy: 0.9593\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1603 - accuracy: 0.9621\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1567 - accuracy: 0.9602\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1525 - accuracy: 0.9602\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1498 - accuracy: 0.9602\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1468 - accuracy: 0.9593\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1430 - accuracy: 0.9612\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1418 - accuracy: 0.9602\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1378 - accuracy: 0.9631\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1348 - accuracy: 0.9564\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1318 - accuracy: 0.9631\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1285 - accuracy: 0.9574\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 0.1272 - accuracy: 0.9583\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1255 - accuracy: 0.9593\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.1234 - accuracy: 0.9574\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1201 - accuracy: 0.9593\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1193 - accuracy: 0.9621\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1171 - accuracy: 0.9640\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1162 - accuracy: 0.9593\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 0.1125 - accuracy: 0.9593\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1121 - accuracy: 0.9621\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 0.1106 - accuracy: 0.9602\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1094 - accuracy: 0.9602\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1067 - accuracy: 0.9593\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.1064 - accuracy: 0.9593\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1053 - accuracy: 0.9602\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1044 - accuracy: 0.9621\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1037 - accuracy: 0.9612\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.1029 - accuracy: 0.9612\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 0.1018 - accuracy: 0.9602\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.0998 - accuracy: 0.9593\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0993 - accuracy: 0.9612\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.0984 - accuracy: 0.9612\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.0975 - accuracy: 0.9583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18f72d9fbe0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "882545fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[314]\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0 314]]\n"
     ]
    }
   ],
   "source": [
    "text='Active'\n",
    "\n",
    "#tokenize\n",
    "token_txt=tokenizer.texts_to_sequences([text])[0]\n",
    "print(token_txt)\n",
    "#padding\n",
    "pad_txt=pad_sequences([token_txt],maxlen=20,padding='pre')\n",
    "print(pad_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9fef2b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.21677235e-09, 2.68734340e-03, 2.12496452e-05, 9.60712671e-01,\n",
       "        3.90172529e-04, 2.26735952e-03, 5.42762782e-03, 6.51537121e-05,\n",
       "        8.85186182e-06, 6.82970767e-06, 1.11219415e-03, 5.65328577e-04,\n",
       "        6.99613452e-07, 6.26581546e-04, 1.40475505e-03, 8.94026816e-05,\n",
       "        7.83340147e-05, 4.53031862e-05, 8.73228316e-07, 3.93251923e-07,\n",
       "        1.45846656e-07, 3.64423729e-04, 3.16016551e-04, 1.42449804e-03,\n",
       "        4.73539997e-03, 6.11004771e-06, 2.88321394e-06, 1.38809573e-05,\n",
       "        4.60164774e-05, 2.24569030e-05, 9.62486211e-03, 7.38871086e-06,\n",
       "        3.37248290e-04, 2.88135561e-06, 2.91402648e-05, 6.71748694e-07,\n",
       "        5.21743141e-06, 1.23017180e-05, 1.29954657e-04, 3.33618773e-05,\n",
       "        1.32114046e-05, 2.38251796e-05, 8.27846733e-08, 3.53335090e-05,\n",
       "        6.31865760e-08, 1.23597729e-07, 6.91635159e-06, 2.63540051e-06,\n",
       "        1.70353296e-08, 1.97344730e-06, 7.74596934e-04, 1.03619790e-07,\n",
       "        1.33856020e-06, 1.94422705e-06, 2.21342566e-06, 2.82070722e-09,\n",
       "        1.95711531e-04, 4.06670239e-07, 3.39598266e-10, 4.77444746e-06,\n",
       "        1.73485739e-06, 1.07526230e-05, 9.81013727e-07, 3.21920226e-07,\n",
       "        2.27625193e-07, 3.13855963e-07, 3.58782557e-07, 4.98731758e-08,\n",
       "        9.20838261e-07, 7.97569101e-07, 7.23376870e-09, 4.46909354e-08,\n",
       "        1.88658552e-04, 3.54182885e-05, 2.49024652e-05, 1.99318424e-06,\n",
       "        3.94015501e-07, 1.23047339e-05, 4.14340828e-09, 1.15957334e-06,\n",
       "        4.07693257e-08, 2.07274788e-04, 2.55197165e-07, 6.28530353e-11,\n",
       "        4.12374357e-06, 1.18152423e-06, 2.92845158e-07, 3.09998342e-07,\n",
       "        9.36158176e-06, 3.76145977e-08, 1.59999765e-08, 4.80534482e-06,\n",
       "        2.26115549e-06, 7.21097706e-07, 8.03257899e-06, 2.14014358e-06,\n",
       "        1.15435178e-07, 3.23544100e-07, 1.26528596e-06, 6.84493244e-08,\n",
       "        6.03350980e-10, 2.56237875e-08, 8.11010239e-07, 4.19784456e-08,\n",
       "        1.34935629e-09, 1.87887542e-06, 1.17567879e-07, 2.31201284e-06,\n",
       "        3.97397389e-06, 5.34898618e-07, 3.31243882e-07, 1.00211801e-05,\n",
       "        4.71404405e-07, 1.62358674e-07, 8.18320245e-07, 2.39705589e-09,\n",
       "        3.33378499e-04, 1.07823750e-08, 1.17064441e-10, 8.79953006e-07,\n",
       "        4.21437517e-06, 1.90469405e-06, 2.24356441e-07, 1.36320388e-09,\n",
       "        1.19318557e-07, 1.82231841e-09, 7.88947204e-07, 7.29180059e-08,\n",
       "        7.94193795e-07, 8.07134981e-08, 6.22985885e-09, 3.64212993e-09,\n",
       "        3.03128544e-08, 4.88666743e-08, 4.10241618e-08, 2.08972267e-07,\n",
       "        9.45791453e-06, 8.16208114e-07, 2.00962197e-04, 1.36741218e-09,\n",
       "        1.34316860e-08, 5.85136490e-08, 1.63623554e-06, 1.92082119e-08,\n",
       "        5.76532511e-06, 8.45900843e-08, 2.76433170e-08, 9.88787633e-06,\n",
       "        2.15196550e-07, 1.97682652e-08, 1.08629630e-08, 1.69828607e-09,\n",
       "        2.81111081e-08, 4.93042407e-09, 1.94213877e-04, 1.74688324e-07,\n",
       "        2.46024865e-05, 2.72594662e-05, 2.36365882e-09, 3.78841542e-05,\n",
       "        2.98747068e-06, 4.57816122e-06, 7.55525207e-07, 6.48229630e-08,\n",
       "        4.17639328e-08, 1.33694666e-09, 7.40942738e-08, 5.90713910e-07,\n",
       "        4.81014104e-06, 2.14876428e-09, 8.14877876e-06, 8.34757088e-07,\n",
       "        2.37894184e-07, 6.39447784e-09, 8.38654273e-07, 7.70633477e-08,\n",
       "        1.36788234e-08, 1.88165727e-09, 4.96681274e-08, 4.06799245e-06,\n",
       "        5.58490274e-06, 6.61048460e-09, 4.42183392e-07, 1.12225997e-07,\n",
       "        1.13846954e-09, 1.21136068e-09, 8.25822521e-10, 8.10415646e-09,\n",
       "        2.40410714e-09, 4.94064789e-09, 7.42564453e-07, 9.37676646e-07,\n",
       "        9.22862426e-08, 6.96842672e-09, 4.26360725e-09, 3.92922583e-10,\n",
       "        1.54494974e-05, 7.95730202e-08, 2.80018337e-08, 2.50764970e-06,\n",
       "        1.10060916e-09, 3.68265884e-09, 4.24474988e-09, 3.19614166e-08,\n",
       "        4.68035495e-08, 1.76553499e-06, 9.99909400e-09, 4.04654665e-09,\n",
       "        5.74006378e-07, 4.13279277e-09, 1.89149620e-08, 4.72518394e-07,\n",
       "        3.19167469e-07, 1.44409199e-07, 1.44964247e-06, 7.08655605e-08,\n",
       "        1.57841072e-07, 5.24629286e-07, 1.83272678e-05, 2.21853654e-07,\n",
       "        1.23274248e-07, 3.37240999e-06, 1.84054136e-06, 1.27434276e-08,\n",
       "        7.64272158e-07, 1.13289457e-06, 6.64929356e-09, 6.94942685e-07,\n",
       "        9.23144086e-08, 4.82459427e-06, 2.12130393e-03, 5.97206395e-07,\n",
       "        1.94228846e-08, 2.71813771e-09, 1.10511955e-08, 7.31000819e-06,\n",
       "        2.06799015e-07, 1.10640341e-09, 1.84138127e-09, 7.45636797e-08,\n",
       "        1.79150049e-06, 3.04135668e-08, 2.97997516e-10, 7.97861555e-10,\n",
       "        2.86936697e-08, 2.14440075e-08, 9.67839355e-07, 3.40227047e-07,\n",
       "        1.22996189e-05, 8.16473888e-10, 1.62353416e-07, 7.54580114e-08,\n",
       "        6.12976905e-08, 1.89240282e-07, 8.71475052e-08, 3.17088222e-08,\n",
       "        4.52195127e-06, 1.29551936e-05, 4.15016466e-08, 3.62861897e-07,\n",
       "        5.51289183e-08, 7.19403559e-08, 5.73089380e-08, 1.28135484e-08,\n",
       "        9.05831214e-08, 5.10253449e-05, 2.67428373e-08, 1.47617520e-05,\n",
       "        4.26488259e-06, 1.54462930e-06, 2.45157310e-07, 7.74148191e-07,\n",
       "        1.62244671e-08, 5.73658895e-07, 1.33756927e-07, 4.76578776e-09,\n",
       "        9.43360501e-09, 1.20899983e-08, 1.65074914e-06, 3.27477672e-08,\n",
       "        1.64591859e-06, 4.90897833e-07, 6.99259942e-07, 4.56090202e-05,\n",
       "        6.47170282e-06, 7.86837063e-06, 2.02486603e-06, 9.22604272e-07,\n",
       "        4.74317963e-09, 3.53967593e-08, 2.05346096e-09, 2.15577420e-05,\n",
       "        3.58945690e-04, 5.20720391e-07, 6.48477494e-10, 9.77033476e-09,\n",
       "        2.11071622e-08, 1.76819637e-09, 3.16393312e-07, 9.66362279e-08,\n",
       "        3.27387717e-08, 1.06576581e-05, 4.53653320e-06, 8.39999484e-06,\n",
       "        1.76071584e-08, 2.49077621e-05, 2.74393165e-06, 1.34565857e-06,\n",
       "        5.36858522e-07, 2.99278859e-08, 5.35105297e-04, 3.95288589e-06,\n",
       "        7.53696554e-07, 2.55677924e-06, 8.55085091e-07, 4.29908027e-07,\n",
       "        2.72035521e-07, 3.77468183e-07, 8.64590011e-10, 6.67757945e-07,\n",
       "        5.32156053e-09, 4.32677643e-06, 7.16902306e-08, 2.42908005e-09,\n",
       "        1.45503316e-06, 3.16765551e-07, 2.81068591e-09, 4.49333129e-07,\n",
       "        1.54185198e-08, 3.09074812e-06, 5.60116587e-06, 5.90261152e-07,\n",
       "        4.23582147e-09, 1.33689826e-09, 6.15700602e-10, 4.17632400e-05,\n",
       "        3.81066521e-08, 2.31475087e-06, 2.51815795e-08, 3.32266616e-04,\n",
       "        2.62895394e-08, 1.28193187e-06, 2.66204303e-09, 1.07822070e-05,\n",
       "        6.35873334e-07, 5.92993388e-08, 4.29814540e-09, 2.36155685e-07,\n",
       "        4.83135532e-09, 2.83025747e-05, 1.89961913e-09, 3.54323575e-08,\n",
       "        2.71905165e-08, 2.08962403e-10, 1.18057855e-07, 2.39699887e-07,\n",
       "        1.39096921e-08, 7.53079348e-07, 4.74150227e-07, 4.06926483e-06,\n",
       "        1.61312869e-07, 1.47529067e-06, 1.88658777e-09, 5.18421928e-08,\n",
       "        2.31578753e-07, 5.29432214e-07, 1.34086372e-06, 1.21906169e-07,\n",
       "        1.20382024e-08, 2.06252389e-06, 8.83574387e-08, 5.44566969e-09,\n",
       "        1.46039852e-07, 5.99724856e-08, 3.57438323e-09, 1.46441508e-07,\n",
       "        5.24769405e-07, 1.87382034e-06, 5.44986767e-09, 2.50261710e-05,\n",
       "        1.42976546e-08, 5.19667651e-07, 8.51901746e-07, 5.48275452e-08,\n",
       "        3.86576285e-05, 2.56497028e-08, 9.91561365e-07, 2.10347906e-07,\n",
       "        1.20868009e-07, 2.35531206e-06, 7.13276593e-09, 1.41477152e-09,\n",
       "        4.68344979e-06, 1.56616323e-07, 1.24758003e-06, 1.01188270e-05,\n",
       "        5.71636065e-07, 1.52522148e-07, 4.07361167e-09, 3.58693256e-07,\n",
       "        6.62773374e-08, 9.71197949e-08, 8.19094748e-09, 1.92571381e-09,\n",
       "        9.84826443e-08, 1.45117358e-08, 7.17981311e-06, 4.56660302e-07,\n",
       "        1.68921972e-07, 1.98706251e-09, 1.38912554e-04, 2.93858602e-06,\n",
       "        1.46454768e-05, 3.12815907e-08, 7.34336140e-07, 1.51634836e-07,\n",
       "        1.53570523e-09, 7.43127428e-04, 3.28838240e-07, 2.34735830e-06,\n",
       "        7.52251872e-05, 6.16020770e-06, 1.25271924e-07, 3.73530867e-07,\n",
       "        2.05183625e-07, 4.05321089e-06, 1.07725754e-07]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(pad_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1234a5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 427)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(pad_txt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe7c4a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "idx=np.argmax(model.predict(pad_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4bd76825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'to': 2,\n",
       " 'learning': 3,\n",
       " 'of': 4,\n",
       " 'a': 5,\n",
       " 'and': 6,\n",
       " 'we': 7,\n",
       " 'data': 8,\n",
       " 'is': 9,\n",
       " 'in': 10,\n",
       " 'machine': 11,\n",
       " 'are': 12,\n",
       " 'which': 13,\n",
       " 'that': 14,\n",
       " '1': 15,\n",
       " 'for': 16,\n",
       " 'as': 17,\n",
       " 'training': 18,\n",
       " 'model': 19,\n",
       " 'fit': 20,\n",
       " 'example': 21,\n",
       " 'or': 22,\n",
       " 'it': 23,\n",
       " 'be': 24,\n",
       " 'spam': 25,\n",
       " 'well': 26,\n",
       " 'e': 27,\n",
       " 'with': 28,\n",
       " '2': 29,\n",
       " 'some': 30,\n",
       " 'how': 31,\n",
       " 'many': 32,\n",
       " 'g': 33,\n",
       " 'there': 34,\n",
       " 'test': 35,\n",
       " 'curve': 36,\n",
       " 'email': 37,\n",
       " 'such': 38,\n",
       " 'can': 39,\n",
       " 'do': 40,\n",
       " 'has': 41,\n",
       " 'learn': 42,\n",
       " 'types': 43,\n",
       " 'computers': 44,\n",
       " 'by': 45,\n",
       " 'between': 46,\n",
       " 'messages': 47,\n",
       " 'rules': 48,\n",
       " 'writing': 49,\n",
       " 'these': 50,\n",
       " '—': 51,\n",
       " 'labeled': 52,\n",
       " 'not': 53,\n",
       " 'than': 54,\n",
       " '3': 55,\n",
       " 'problems': 56,\n",
       " 'csc': 57,\n",
       " 'might': 58,\n",
       " 'when': 59,\n",
       " 'on': 60,\n",
       " 'introduction': 61,\n",
       " 'set': 62,\n",
       " 'examples': 63,\n",
       " 'program': 64,\n",
       " 'distinguish': 65,\n",
       " 'valid': 66,\n",
       " 'try': 67,\n",
       " 'an': 68,\n",
       " 'from': 69,\n",
       " 'provide': 70,\n",
       " 'have': 71,\n",
       " 'ways': 72,\n",
       " 'view': 73,\n",
       " 'all': 74,\n",
       " 'statistics': 75,\n",
       " 'often': 76,\n",
       " 'methods': 77,\n",
       " 'two': 78,\n",
       " 'used': 79,\n",
       " 'make': 80,\n",
       " 'supervised': 81,\n",
       " 'given': 82,\n",
       " 'use': 83,\n",
       " 'you': 84,\n",
       " 'tools': 85,\n",
       " 'us': 86,\n",
       " 'they': 87,\n",
       " 'should': 88,\n",
       " 'done': 89,\n",
       " 'wish': 90,\n",
       " 'write': 91,\n",
       " 'unwanted': 92,\n",
       " 'simple': 93,\n",
       " 'certain': 94,\n",
       " 'however': 95,\n",
       " 'resulting': 96,\n",
       " 'worse': 97,\n",
       " 'emails': 98,\n",
       " 'will': 99,\n",
       " 'way': 100,\n",
       " '”': 101,\n",
       " 'them': 102,\n",
       " 'task': 103,\n",
       " 'solution': 104,\n",
       " 'algorithm': 105,\n",
       " '“spam”': 106,\n",
       " 'automatically': 107,\n",
       " 'intelligence': 108,\n",
       " 'knowledge': 109,\n",
       " 'intelligent': 110,\n",
       " 'trying': 111,\n",
       " 'language': 112,\n",
       " 'instead': 113,\n",
       " 'applied': 114,\n",
       " 'vast': 115,\n",
       " 'more': 116,\n",
       " 'important': 117,\n",
       " 'collection': 118,\n",
       " 'about': 119,\n",
       " 'new': 120,\n",
       " 'filtering': 121,\n",
       " 'other': 122,\n",
       " 'copyright': 123,\n",
       " 'c': 124,\n",
       " '2011': 125,\n",
       " 'aaron': 126,\n",
       " 'hertzmann': 127,\n",
       " 'david': 128,\n",
       " 'fleet': 129,\n",
       " '411': 130,\n",
       " 'd11': 131,\n",
       " 'most': 132,\n",
       " 'common': 133,\n",
       " 'where': 134,\n",
       " 'outputs': 135,\n",
       " 'regression': 136,\n",
       " 'actions': 137,\n",
       " 'detection': 138,\n",
       " '4': 139,\n",
       " 'expensive': 140,\n",
       " 'problem': 141,\n",
       " 'figure': 142,\n",
       " '1d': 143,\n",
       " 'points': 144,\n",
       " 'noisy': 145,\n",
       " 'want': 146,\n",
       " 'requires': 147,\n",
       " 'choices': 148,\n",
       " 'parameterize': 149,\n",
       " 'function': 150,\n",
       " 'quality': 151,\n",
       " 'squared': 152,\n",
       " 'error': 153,\n",
       " 'models': 154,\n",
       " 'predictions': 155,\n",
       " 'future': 156,\n",
       " 'but': 157,\n",
       " 'say': 158,\n",
       " 'properties': 159,\n",
       " 'practice': 160,\n",
       " 'broadly': 161,\n",
       " 'speaking': 162,\n",
       " 'allow': 163,\n",
       " '“teach”': 164,\n",
       " 'perform': 165,\n",
       " 'tasks': 166,\n",
       " 'providing': 167,\n",
       " 'suppose': 168,\n",
       " 'could': 169,\n",
       " 'flagging': 170,\n",
       " 'contain': 171,\n",
       " 'features': 172,\n",
       " 'word': 173,\n",
       " '“viagra”': 174,\n",
       " 'obviously': 175,\n",
       " 'fake': 176,\n",
       " 'headers': 177,\n",
       " 'accurately': 178,\n",
       " 'text': 179,\n",
       " 'actually': 180,\n",
       " 'quite': 181,\n",
       " 'difficult': 182,\n",
       " 'either': 183,\n",
       " 'missed': 184,\n",
       " 'lost': 185,\n",
       " 'spammers': 186,\n",
       " 'actively': 187,\n",
       " 'adjust': 188,\n",
       " 'send': 189,\n",
       " 'order': 190,\n",
       " 'trick': 191,\n",
       " 'strategies': 192,\n",
       " '“vi': 193,\n",
       " 'gr': 194,\n",
       " 'effective': 195,\n",
       " 'keeping': 196,\n",
       " 'up': 197,\n",
       " 'date': 198,\n",
       " 'quickly': 199,\n",
       " 'becomes': 200,\n",
       " 'insurmountable': 201,\n",
       " 'fortunately': 202,\n",
       " 'provided': 203,\n",
       " 'modern': 204,\n",
       " 'filters': 205,\n",
       " '“learned”': 206,\n",
       " 'manually': 207,\n",
       " '“ham”': 208,\n",
       " 'algorithms': 209,\n",
       " 'diverse': 210,\n",
       " 'exciting': 211,\n",
       " 'field': 212,\n",
       " 'multiple': 213,\n",
       " 'defining': 214,\n",
       " 'artifical': 215,\n",
       " 'central': 216,\n",
       " 'human': 217,\n",
       " 'likewise': 218,\n",
       " 'also': 219,\n",
       " 'essential': 220,\n",
       " 'building': 221,\n",
       " 'machines': 222,\n",
       " 'years': 223,\n",
       " 'effort': 224,\n",
       " 'ai': 225,\n",
       " 'shown': 226,\n",
       " 'build': 227,\n",
       " 'programming': 228,\n",
       " 'cannot': 229,\n",
       " 'automatic': 230,\n",
       " 'crucial': 231,\n",
       " 'humans': 232,\n",
       " 'born': 233,\n",
       " 'ability': 234,\n",
       " 'understand': 235,\n",
       " 'makes': 236,\n",
       " 'sense': 237,\n",
       " 'software': 238,\n",
       " 'engineering': 239,\n",
       " 'allows': 240,\n",
       " 'easier': 241,\n",
       " 'code': 242,\n",
       " 'traditional': 243,\n",
       " 'stats': 244,\n",
       " 'marriage': 245,\n",
       " 'computer': 246,\n",
       " 'science': 247,\n",
       " 'computational': 248,\n",
       " 'techniques': 249,\n",
       " 'statistical': 250,\n",
       " 'been': 251,\n",
       " 'number': 252,\n",
       " 'contexts': 253,\n",
       " 'beyond': 254,\n",
       " 'typical': 255,\n",
       " 'designed': 256,\n",
       " 'different': 257,\n",
       " 'considerations': 258,\n",
       " 'speed': 259,\n",
       " 'accuracy': 260,\n",
       " 'broken': 261,\n",
       " 'into': 262,\n",
       " 'phases': 263,\n",
       " 'learned': 264,\n",
       " 'application': 265,\n",
       " 'decisions': 266,\n",
       " 'case': 267,\n",
       " 'constitutes': 268,\n",
       " 'ham': 269,\n",
       " 'each': 270,\n",
       " 'message': 271,\n",
       " 'receive': 272,\n",
       " 'classify': 273,\n",
       " 'main': 274,\n",
       " 'correct': 275,\n",
       " 'answers': 276,\n",
       " '“ham': 277,\n",
       " 'classification': 278,\n",
       " 'discrete': 279,\n",
       " 'labels': 280,\n",
       " 'real': 281,\n",
       " 'valued': 282,\n",
       " 'unsupervised': 283,\n",
       " 'unlabeled': 284,\n",
       " 'analyze': 285,\n",
       " 'discover': 286,\n",
       " 'patterns': 287,\n",
       " 'within': 288,\n",
       " 'dimension': 289,\n",
       " 'reduction': 290,\n",
       " 'clustering': 291,\n",
       " 'reinforcement': 292,\n",
       " 'agent': 293,\n",
       " 'robot': 294,\n",
       " 'controller': 295,\n",
       " 'seeks': 296,\n",
       " 'optimal': 297,\n",
       " 'take': 298,\n",
       " 'based': 299,\n",
       " 'outcomes': 300,\n",
       " 'past': 301,\n",
       " 'semi': 302,\n",
       " 'only': 303,\n",
       " 'subset': 304,\n",
       " 'time': 305,\n",
       " 'series': 306,\n",
       " 'forecasting': 307,\n",
       " 'financial': 308,\n",
       " 'markets': 309,\n",
       " 'anomaly': 310,\n",
       " 'fault': 311,\n",
       " 'factories': 312,\n",
       " 'surveillance': 313,\n",
       " 'active': 314,\n",
       " 'obtaining': 315,\n",
       " 'so': 316,\n",
       " 'must': 317,\n",
       " 'determine': 318,\n",
       " 'acquire': 319,\n",
       " 'others': 320,\n",
       " 'shows': 321,\n",
       " 'goal': 322,\n",
       " 'few': 323,\n",
       " 'best': 324,\n",
       " 'infinitely': 325,\n",
       " 'curves': 326,\n",
       " 'because': 327,\n",
       " 'even': 328,\n",
       " 'precisely': 329,\n",
       " 'hence': 330,\n",
       " 'explain': 331,\n",
       " 'linear': 332,\n",
       " 'quadratic': 333,\n",
       " 'sinusoidal': 334,\n",
       " 'what': 335,\n",
       " 'criteria': 336,\n",
       " 'objective': 337,\n",
       " 'judge': 338,\n",
       " 'fitting': 339,\n",
       " 'measure': 340,\n",
       " 'terms': 341,\n",
       " 'fitted': 342,\n",
       " 'minimizing': 343,\n",
       " 'usually': 344,\n",
       " 'called': 345,\n",
       " 'least': 346,\n",
       " 'squares': 347,\n",
       " 'estimate': 348,\n",
       " 'parameters': 349,\n",
       " 'very': 350,\n",
       " 'optimize': 351,\n",
       " 'long': 352,\n",
       " 'willing': 353,\n",
       " 'wait': 354,\n",
       " 'approximations': 355,\n",
       " 'handtuning': 356,\n",
       " 'ideally': 357,\n",
       " 'find': 358,\n",
       " 'useful': 359,\n",
       " 'situations': 360,\n",
       " 'although': 361,\n",
       " 'ultimately': 362,\n",
       " 'care': 363,\n",
       " 'works': 364,\n",
       " 'fits': 365,\n",
       " 'performs': 366,\n",
       " 'poorly': 367,\n",
       " 'overfit': 368,\n",
       " 'i': 369,\n",
       " 'input': 370,\n",
       " 'particularly': 371,\n",
       " 'relevant': 372,\n",
       " 'at': 373,\n",
       " 'hand': 374,\n",
       " 'figures': 375,\n",
       " 'top': 376,\n",
       " 'row': 377,\n",
       " 'bottom': 378,\n",
       " 'left': 379,\n",
       " 'refered': 380,\n",
       " 'noise': 381,\n",
       " 'this': 382,\n",
       " 'happens': 383,\n",
       " 'does': 384,\n",
       " 'generalize': 385,\n",
       " 'rather': 386,\n",
       " 'produces': 387,\n",
       " 'much': 388,\n",
       " 'less': 389,\n",
       " 'accurate': 390,\n",
       " 'hoped': 391,\n",
       " 'provides': 392,\n",
       " 'wide': 393,\n",
       " 'selection': 394,\n",
       " 'options': 395,\n",
       " 'answer': 396,\n",
       " 'questions': 397,\n",
       " 'along': 398,\n",
       " 'experience': 399,\n",
       " 'community': 400,\n",
       " 'tend': 401,\n",
       " 'successful': 402,\n",
       " 'particular': 403,\n",
       " 'class': 404,\n",
       " 'advanced': 405,\n",
       " 'automating': 406,\n",
       " 'selecting': 407,\n",
       " 'alternative': 408,\n",
       " 'beautiful': 409,\n",
       " 'theory': 410,\n",
       " 'assists': 411,\n",
       " 'gaining': 412,\n",
       " 'deeper': 413,\n",
       " 'understanding': 414,\n",
       " 'no': 415,\n",
       " 'single': 416,\n",
       " '“silver': 417,\n",
       " 'bullet”': 418,\n",
       " 'using': 419,\n",
       " 'your': 420,\n",
       " 'own': 421,\n",
       " 'prior': 422,\n",
       " 'experimentation': 423,\n",
       " 'solve': 424,\n",
       " 'amazing': 425,\n",
       " 'things': 426}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df146b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n"
     ]
    }
   ],
   "source": [
    "for word ,index in tokenizer.word_index.items():\n",
    "    if index==idx:\n",
    "        print(word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8d4d1c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning is\n",
      "Machine learning is a\n",
      "Machine learning is a set\n",
      "Machine learning is a set of\n",
      "Machine learning is a set of tools\n",
      "Machine learning is a set of tools that\n",
      "Machine learning is a set of tools that broadly\n",
      "Machine learning is a set of tools that broadly speaking\n",
      "Machine learning is a set of tools that broadly speaking allow\n",
      "Machine learning is a set of tools that broadly speaking allow us\n"
     ]
    }
   ],
   "source": [
    "text='Machine learning'\n",
    "for i in range(10):\n",
    "    #tokenize\n",
    "    token_txt=tokenizer.texts_to_sequences([text])[0]\n",
    "    #padding\n",
    "    pad_txt=pad_sequences([token_txt],maxlen=20,padding='pre')\n",
    "    idx=np.argmax(model.predict(pad_txt))\n",
    "    \n",
    "    for word ,index in tokenizer.word_index.items():\n",
    "        if index==idx:\n",
    "            text=text+\" \"+word\n",
    "            print(text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea5b7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463cd802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
